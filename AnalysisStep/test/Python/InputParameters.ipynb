{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/09\n"
     ]
    }
   ],
   "source": [
    "from trainlib.FileCollection import FileCollection\n",
    "from trainlib.config import Config\n",
    "from trainlib.ConfigFileHandler import ConfigFileHandler\n",
    "from trainlib.ConfigFileUtils import ConfigFileUtils\n",
    "import trainlib.cuts as cuts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from scipy import interpolate\n",
    "import scipy.integrate as integrate\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs_depscipy/3.0-fmblme3/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#candidate_branches = [\"PFMET\", \"nCleanedJetsPt30\", \"nCleanedJetsPt30BTagged_bTagSF\", \"nExtraLep\", \"ZZMass\", \"nExtraZ\", \"Z1Mass\", \"Z2Mass\", \"Z1Pt\", \"Z2Pt\", \"ZZMassErr\", \"ZZPt\", \"ZZEta\", \"ZZPhi\", \"Z1Flav\", \"Z2Flav\", \"costhetastar\", \"helphi\", \"helcosthetaZ1\", \"helcosthetaZ2\", \"phistarZ1\", \"phistarZ2\", \"xi\", \"xistar\"]\n",
    "candidate_branches = [\"PFMET\", \"nCleanedJetsPt30\", \"nCleanedJetsPt30BTagged_bTagSF\", \"nExtraLep\", \"ZZMass\", \"nExtraZ\", \"Z1Mass\", \"Z2Mass\", \"Z1Pt\", \"Z2Pt\", \"ZZMassErr\", \"ZZPt\", \"ZZEta\", \"ZZPhi\", \"Z1Flav\", \"Z2Flav\"]\n",
    "MELA_branches = [\"D_VBF2j_ggH_ME\", \"D_VBF1j_ggH_ME\", \"D_WHh_ggH_ME\", \"D_ZHh_ggH_ME\", \"D_WHh_ZHh_ME\", \"D_VBF2j_WHh_ME\", \"D_VBF2j_ZHh_ME\"]\n",
    "#list_branches = [\"Jet\", \"Lep\", \"ExtraLep\"]\n",
    "list_branches = [\"Jet\", \"ExtraLep\"]\n",
    "pt_limits = [30.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allbranches = [\"JetPt\", \"JetEta\", \"JetPhi\", \"LepPt\", \"LepEta\", \"LepPhi\", \"ExtraLepPt\", \"ExtraLepEta\", \"ExtraLepPhi\"] + candidate_branches + MELA_branches + [\"LHEAssociatedParticleId\", \"GenAssocLep1Id\", \"GenAssocLep2Id\", \"training_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MC_path = \"/data_CMS/cms/wind/CJLST_NTuples_randomizeda/\"\n",
    "MC_path = \"/data_CMS/cms/wind/CJLST_NTuples/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def WHhadr0j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def WHhadr01j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def WHhadr1j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def WHhadr2j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def ZHhadr0j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def ZHhadr01j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def ZHhadr1j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def ZHhadr2j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def mZZ0j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def mZZ01j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def mZZ1j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def mZZ2j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the cuts without any m4l restriction imposed\n",
    "def WHhadr0j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def WHhadr01j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def WHhadr1j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def WHhadr2j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def ZHhadr0j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def ZHhadr01j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def ZHhadr1j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def ZHhadr2j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def mZZ0j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def mZZ01j_cut(row):\n",
    "    return (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def mZZ1j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def mZZ2j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collections = {\"VBF2j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"VBF1j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"VBF0j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"VBF01j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"VBF\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": cuts.mZZ_cut},\n",
    "            \"ggH2j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"ggH1j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"ggH0j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"ggH01j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"ggH\" : {MC_path + \"ggH125/ZZ4lAnalysis.root\": cuts.mZZ_cut},\n",
    "            \"WHh2j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr2j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr2j_cut},\n",
    "            \"WHh1j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr1j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr1j_cut},\n",
    "            \"WHh0j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr0j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr0j_cut},\n",
    "            \"WHh\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut},\n",
    "            \"WHh01j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr01j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr01j_cut},\n",
    "            \"WHl\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut},\n",
    "            \"ZHh2j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr2j_cut},\n",
    "            \"ZHh1j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr1j_cut},\n",
    "            \"ZHh01j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr01j_cut},\n",
    "            \"ZHh0j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr0j_cut},\n",
    "            \"ZHh\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHhadr_cut},\n",
    "            \"ZHl\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHlept_cut},\n",
    "            \"ttHh\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHhadr_cut},\n",
    "            \"ttHl\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHlept_cut},\n",
    "            \"ZHMET\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHMET_cut}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all the model combinations for which neural networks are currently trained\n",
    "discriminant_pairs = [(\"VBF2j\", \"ggH2j\"), (\"VBF1j\", \"ggH1j\"), (\"VBF0j\", \"ggH0j\"), (\"WHh2j\", \"ggH2j\"), \n",
    "                     (\"WHh1j\", \"ggH1j\"), (\"WHh0j\", \"ggH0j\"), (\"ZHh2j\", \"ggH2j\"), (\"ZHh1j\", \"ggH1j\"), \n",
    "                      (\"ZHh0j\", \"ggH0j\"), (\"WHh2j\", \"ZHh2j\"), (\"WHh01j\", \"ZHh01j\"), (\"VBF2j\", \"WHh2j\"),\n",
    "                     (\"VBF1j\", \"WHh1j\"), (\"VBF0j\", \"WHh0j\"), (\"VBF2j\", \"ZHh2j\"), (\"VBF1j\", \"ZHh1j\"), \n",
    "                      (\"VBF0j\", \"ZHh0h\"), (\"WHl\", \"ggH\"), (\"WHl\", \"VBF\"), (\"WHl\", \"WHh\"), (\"WHl\", \"ZHh\"),\n",
    "                     (\"WHl\", \"ZHl\"), (\"WHl\", \"ZHMET\"), (\"WHl\", \"ttHh\"), (\"WHl\", \"ttHl\"), (\"ZHh\", \"ZHl\"),\n",
    "                     (\"ZHh\", \"ZHMET\"), (\"ZHh\", \"ttHh\"), (\"ZHh\", \"ttHl\"), (\"ZHl\", \"ggH\"), (\"ZHl\", \"VBF\"),\n",
    "                     (\"ZHl\", \"WHh\"), (\"ZHl\", \"ZHMET\"), (\"ZHl\", \"ttHh\"), (\"ZHl\", \"ttHl\"), (\"ZHMET\", \"ggH\"),\n",
    "                     (\"ZHMET\", \"VBF\"), (\"ZHMET\", \"WHh\"), (\"ZHMET\", \"ttHh\"), (\"ZHMET\", \"ttHl\"), (\"ttHh\", \"ggH\"),\n",
    "                      (\"ttHh\", \"VBF\"), (\"ttHh\", \"WHh\"), (\"ttHh\", \"ttHl\"), (\"ttHl\", \"ggH\"), (\"ttHl\", \"VBF\"),\n",
    "                     (\"ttHl\", \"WHh\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_order(df, col_basename, sorted_column, columns, order):\n",
    "    def get_index(row, order, col_basename, sorted_column):\n",
    "        sorted_column = row[col_basename + sorted_column]\n",
    "        if order >= len(sorted_column):\n",
    "            return -1\n",
    "        else:\n",
    "            return np.flipud(np.argsort(sorted_column))[order]\n",
    "    \n",
    "    index_column = pd.DataFrame(df.transform(lambda row: get_index(row, order, col_basename, sorted_column), axis = 1, raw = True))\n",
    "    index_column.columns = [\"index\"]\n",
    "    df_temp = pd.concat([index_column, df], axis = 1)\n",
    "    \n",
    "    def get_element(row, column_name):\n",
    "        if row[\"index\"] == -1:\n",
    "            return 0\n",
    "        else:\n",
    "            return row[column_name][row[\"index\"]]\n",
    "        \n",
    "    extracted_cols = pd.DataFrame()\n",
    "    for column in columns:\n",
    "        extracted_col = pd.DataFrame(df_temp.transform(lambda row: get_element(row, col_basename + column), axis = 1, raw = True))\n",
    "        extracted_col.columns = [col_basename + column + \"(\" + col_basename + \"Pt|\" + str(order) + \")\"]\n",
    "        extracted_cols = pd.concat([extracted_cols, extracted_col], axis = 1)\n",
    "        \n",
    "    return extracted_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, col_basenames, sorted_column, columns, orders, pt_limits):\n",
    "    all_extracted = pd.DataFrame()\n",
    "    for col_basename, pt_limit in zip(col_basenames, pt_limits):\n",
    "        for order in orders:\n",
    "            extracted = extract_order(df, col_basename, sorted_column, columns, order)\n",
    "            mask = extracted[col_basename + \"Pt(\" + col_basename + \"Pt|\" + str(order) + \")\"] < pt_limit\n",
    "            extracted[mask] = 0.0\n",
    "\n",
    "            all_extracted = pd.concat([all_extracted, extracted], axis = 1)\n",
    "            \n",
    "    return all_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits):\n",
    "    H1_df = H1_coll.get_data(read_branches, 0.0, 1.0)\n",
    "    H0_df = H0_coll.get_data(read_branches, 0.0, 1.0)\n",
    "    \n",
    "    H1_list_df = prepare_data(H1_df, list_branches, \"Pt\", [\"Pt\", \"Eta\", \"Phi\"], range(4), pt_limits)\n",
    "    H0_list_df = prepare_data(H0_df, list_branches, \"Pt\", [\"Pt\", \"Eta\", \"Phi\"], range(4), pt_limits)\n",
    "    \n",
    "    list_branches_unrolled = H1_list_df.columns\n",
    "            \n",
    "    H1_df = pd.concat([H1_df, H1_list_df], axis = 1)\n",
    "    H0_df = pd.concat([H0_df, H0_list_df], axis = 1)        \n",
    "    \n",
    "    complete_input_branches = np.concatenate([input_branches, list_branches_unrolled])\n",
    "            \n",
    "    H1_df = H1_df[complete_input_branches]\n",
    "    H0_df = H0_df[complete_input_branches]\n",
    "    \n",
    "    return H1_df, H0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_dmatrix(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits):\n",
    "    H1_df, H0_df = get_data(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    complete_input_branches = H1_df.columns\n",
    "    print \"number of input variables: \" + str(len(complete_input_branches))\n",
    "    print \"final list of inputs: \" + str(complete_input_branches)\n",
    "    \n",
    "    # try with the same weights as used later in the neural network training, to balance out some (very)\n",
    "    # unbalanced datasets\n",
    "    H1_class_weight = 1.0 + float(len(H0_df)) / float(len(H1_df))\n",
    "    H0_class_weight = 1.0 + float(len(H1_df)) / float(len(H0_df))\n",
    "    \n",
    "    print \"using class weights: \" + str(H1_class_weight) + \" (H1), \" + str(H0_class_weight) + \" (H0)\"\n",
    "    \n",
    "    H1_weights = np.full(len(H1_df), H1_class_weight)\n",
    "    H0_weights = np.full(len(H0_df), H0_class_weight)\n",
    "    \n",
    "    H1_data = H1_df.as_matrix()\n",
    "    H0_data = H0_df.as_matrix()\n",
    "    H1_target = np.ones(np.shape(H1_data)[0])\n",
    "    H0_target = np.zeros(np.shape(H0_data)[0])\n",
    "    \n",
    "    target = np.concatenate([H1_target, H0_target])\n",
    "    data = np.concatenate([H1_data, H0_data])\n",
    "    weights = np.concatenate([H1_weights, H0_weights])\n",
    "    \n",
    "    dmatrix = xgb.DMatrix(data, label = target, feature_names = complete_input_branches, weight = weights)\n",
    "    \n",
    "    return dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_correlation(source, corr_branches, mandatory_branches, optional_branches, list_branches, pt_limits):    \n",
    "    coll = FileCollection(collections[source], 0.0, 0.5)\n",
    "    \n",
    "    input_branches = [branch for branch in mandatory_branches]\n",
    "    \n",
    "    for optional_branch in optional_branches:\n",
    "        if \"0j\" in source and (\"0j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        if \"1j\" in source and (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        if \"2j\" in source and (\"2j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "\n",
    "    df, _ = get_data(coll, coll, allbranches, input_branches, list_branches, pt_limits)\n",
    "\n",
    "    df = df[corr_branches]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    cax = ax.matshow(df.corr(), vmin = -1.0, vmax = 1.0, cmap = \"RdBu\")\n",
    "    \n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    ax.set_yticklabels([''] + corr_branches)\n",
    "    ax.set_xticklabels([''] + corr_branches, rotation = 'vertical')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interpolating_function(data, bins):\n",
    "    bin_centers = [np.mean([bins[i], bins[i + 1]]) for i in range(len(bins) - 1)]\n",
    "    intf = interpolate.interp1d(bin_centers, data, kind = \"linear\")\n",
    "    interpolated_function = lambda x: intf(x) if x > bin_centers[0] and x < bin_centers[-1] else 0\n",
    "    \n",
    "    return interpolated_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binned_data(df, branch):\n",
    "    data = df[branch].as_matrix()\n",
    "    weights = df[\"training_weight\"].as_matrix()\n",
    "    \n",
    "    # set the bin width\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    bin_width = max(2 * (q75 - q25) / len(data)**0.33, 0.005)\n",
    "\n",
    "    data_max = np.max(data)\n",
    "    data_min = np.min(data)\n",
    "    bins = np.arange(data_min, data_max + bin_width, bin_width)\n",
    "    \n",
    "    weights = weights / (np.sum(weights) * bin_width)\n",
    "    \n",
    "    hist = np.histogram(data, bins = bins, weights = weights)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_list_separation(disc_pair, mandatory_branches, optional_branches, list_branches, pt_limits):\n",
    "    H1_name = disc_pair[0]\n",
    "    H0_name = disc_pair[1]\n",
    "    \n",
    "    input_branches = [branch for branch in mandatory_branches]\n",
    "    \n",
    "    for optional_branch in optional_branches:\n",
    "        if (\"0j\" in H1_name or \"0j\" in H0_name) and (\"0j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)  \n",
    "        elif (\"1j\" in H1_name or \"1j\" in H0_name) and (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "        elif (\"2j\" in H1_name or \"2j\" in H0_name) and not (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "    # needed to build the histograms\n",
    "    input_branches.append(\"training_weight\")\n",
    "    \n",
    "    H1_coll = FileCollection(collections[H1_name], 0.0, 0.5)\n",
    "    H0_coll = FileCollection(collections[H0_name], 0.0, 0.5)\n",
    "    \n",
    "    H1_df, H0_df = get_data(H1_coll, H0_coll, allbranches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    available_branches = H1_df.columns\n",
    "    \n",
    "    implist = {}\n",
    "    for branch in available_branches:\n",
    "                \n",
    "        if \"training_weight\" not in branch:\n",
    "            data_H1, bins_H1 = get_binned_data(H1_df, branch)\n",
    "            data_H0, bins_H0 = get_binned_data(H0_df, branch)\n",
    "\n",
    "            if(len(data_H1) > 0):\n",
    "                H1_func = get_interpolating_function(data_H1, bins_H1)\n",
    "                H0_func = get_interpolating_function(data_H0, bins_H0)\n",
    "\n",
    "                # compute the separation in this branch\n",
    "                global_min = np.min(np.concatenate([bins_H0, bins_H1]))\n",
    "                global_max = np.max(np.concatenate([bins_H0, bins_H1]))\n",
    "\n",
    "                separation_func = lambda x: (H1_func(x) + H0_func(x)) * (H1_func(x) - H0_func(x))**2\n",
    "\n",
    "                sep = integrate.quad(separation_func, global_min, global_max)[0]\n",
    "            else:\n",
    "                sep = 0.0\n",
    "                \n",
    "            print \"separation for \" + branch + \" = \" + str(sep)\n",
    "            implist[branch] = sep\n",
    "        \n",
    "    # normalize the importance list\n",
    "    impsum = sum([val for key, val in implist.iteritems()])\n",
    "    for key in implist.keys():\n",
    "        implist[key] /= impsum\n",
    "        \n",
    "    return None, None, implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_list_BDT(disc_pair, mandatory_branches, optional_branches, list_branches, pt_limits):\n",
    "    H1_name = disc_pair[0]\n",
    "    H0_name = disc_pair[1]\n",
    "    \n",
    "    # first assemble the list of branches that can serve as input: it will *always* contain the mandatory branches,\n",
    "    # and *can* contain some of the optional branches, if the name of the categories allows it\n",
    "    input_branches = [branch for branch in mandatory_branches]\n",
    "    \n",
    "    for optional_branch in optional_branches:\n",
    "        if (\"0j\" in H1_name or \"0j\" in H0_name) and (\"0j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)  \n",
    "        elif (\"1j\" in H1_name or \"1j\" in H0_name) and (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "        elif (\"2j\" in H1_name or \"2j\" in H0_name) and not (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        # the fully inclusive categories (i.e. those with NO \"xxj\" in their name, can not use MELA, since there may\n",
    "        # be events with low number of jets contained)\n",
    "    \n",
    "    # get the training data for the BDT ...\n",
    "    H1_coll_train = FileCollection(collections[H1_name], 0.0, 0.5)\n",
    "    H0_coll_train = FileCollection(collections[H0_name], 0.0, 0.5)\n",
    "    \n",
    "    dtrain = get_data_dmatrix(H1_coll_train, H0_coll_train, allbranches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    # ... and the validation data as well\n",
    "    H1_coll_val = FileCollection(collections[H1_name], 0.5, 1.0)\n",
    "    H0_coll_val = FileCollection(collections[H0_name], 0.5, 1.0)\n",
    "    dval = get_data_dmatrix(H1_coll_val, H0_coll_val, allbranches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "    \n",
    "    # perform the training\n",
    "    # try different tree depths and choose the one that gives the best RMSE (i.e. avoid too deep trees to start with)\n",
    "        \n",
    "    params = {'eta': 0.01, 'silent': 1, 'gamma': 0.5, 'objective': 'binary:logistic'}\n",
    "    params['nthread'] = 4\n",
    "    params['eval_metric'] = 'rmse'\n",
    "    max_num_rounds = 2000\n",
    "    \n",
    "    best_loss = 1e6\n",
    "    best_imp = None\n",
    "    best_params = None\n",
    "    for tree_depth in range(1,8):\n",
    "        params['max_depth'] = tree_depth\n",
    "        \n",
    "        bst = xgb.train(params, dtrain, max_num_rounds, evals = evallist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "    \n",
    "        pred = bst.predict(dval)\n",
    "        cur_loss = np.sqrt(mean_squared_error(pred, dval.get_label()))\n",
    "        cur_imp = bst.get_fscore()\n",
    "\n",
    "        print \"for max_depth = \" + str(params['max_depth']) + \": loss = \" + str(cur_loss)\n",
    "        \n",
    "        if cur_loss < best_loss:\n",
    "            best_loss = cur_loss\n",
    "            best_imp = copy.copy(cur_imp)\n",
    "            best_params = copy.copy(params)\n",
    "            \n",
    "    # normalize the usage score w.r.t. the total score (i.e. sum of all individuals)\n",
    "    score_sum = sum([val for key, val in best_imp.iteritems()])\n",
    "    used_variables = {key: val / float(score_sum) for key, val in sorted(best_imp.iteritems(), key = lambda x: x[1], reverse = True)}           \n",
    "    return best_params, dtrain.feature_names, used_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_histogram(df, branch, label):\n",
    "    data = df[branch].as_matrix()\n",
    "    weights = df[\"training_weight\"].as_matrix()\n",
    "    \n",
    "    # set the bin width\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    bin_width = max(2 * (q75 - q25) / len(data)**0.33, 0.005)\n",
    "\n",
    "    data_max = np.max(data)\n",
    "    data_min = np.min(data)\n",
    "    bins = np.arange(data_min, data_max + bin_width, bin_width)\n",
    "    \n",
    "    weights = weights / (np.sum(weights) * bin_width)\n",
    "    \n",
    "    fig = plt.hist(data, bins = bins, weights = weights, alpha = 0.5, label = label)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_branch(disc_pair, branch, start_fraction = 0.0, end_fraction = 1.0):\n",
    "    H1_name = disc_pair[0]\n",
    "    H0_name = disc_pair[1]\n",
    "    \n",
    "    # get the training data for the BDT ...\n",
    "    H1_coll = FileCollection(collections[H1_name], start_fraction, end_fraction)\n",
    "    H0_coll = FileCollection(collections[H0_name], start_fraction, end_fraction)\n",
    "    \n",
    "    H1_df, H0_df = get_data(H1_coll, H0_coll, allbranches, allbranches, list_branches, pt_limits)\n",
    "    \n",
    "    plt.figure()\n",
    "    H1_hist = get_histogram(H1_df, branch, H1_name)\n",
    "    H0_hist = get_histogram(H0_df, branch, H0_name)\n",
    "    \n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_variables(discs):\n",
    "    plotframe = pd.DataFrame()\n",
    "    \n",
    "    for disc in discs:\n",
    "        _, _, implist = get_feature_importance_list_BDT(disc, candidate_branches, MELA_branches, list_branches, pt_limits)\n",
    "        \n",
    "        # cut the list to select only the 95% most important variables\n",
    "        cutimplist = {key: val for key, val in implist.iteritems() if val > 0.00}\n",
    "        curframe = pd.DataFrame(cutimplist, index = [len(plotframe)])\n",
    "        \n",
    "        plotframe = pd.concat([plotframe, curframe])\n",
    "        \n",
    "    plotframe = plotframe.fillna(0.0)\n",
    "    \n",
    "    print plotframe\n",
    "    print \"number of pre-selected input variables = \" + str(len(plotframe.columns))\n",
    "    \n",
    "    # start the plotting\n",
    "    parameters = plotframe.columns\n",
    "    plotdata = np.transpose(plotframe.as_matrix())\n",
    "    \n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize=(10,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(plotdata, cmap = 'Blues')\n",
    "    \n",
    "    # make axis labels\n",
    "    disclabels = []\n",
    "    for disc in discs:\n",
    "        if \"0j\" in disc[0] or \"0j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('0j', '', disc[0]) + \"_\" + re.sub('0j', '', disc[1]) + \"_0j\")\n",
    "        elif \"01j\" in disc[0] or \"01j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('01j', '', disc[0]) + \"_\" + re.sub('01j', '', disc[1]) + \"_01j\")\n",
    "        elif \"1j\" in disc[0] or \"1j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('1j', '', disc[0]) + \"_\" + re.sub('1j', '', disc[1]) + \"_1j\")\n",
    "        elif \"2j\" in disc[0] or \"2j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('2j', '', disc[0]) + \"_\" + re.sub('2j', '', disc[1]) + \"_2j\")\n",
    "        else:\n",
    "            disclabels.append('D_' + disc[0] + \"_\" + disc[1] + \"_2j\")\n",
    "            \n",
    "    disclabels = np.concatenate([[''], np.array(disclabels)])\n",
    "    parameters = np.concatenate([[''], np.array(parameters)])\n",
    "        \n",
    "    ax.set_xticklabels(disclabels, rotation = 'vertical')\n",
    "    ax.set_yticklabels(parameters)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    # sort the used variables according to their importance\n",
    "    sorted_implist = []\n",
    "    for key, val in sorted(cutimplist.iteritems(), key = lambda x: x[1], reverse = True):\n",
    "        sorted_implist.append((key, val))\n",
    "    \n",
    "    return fig, sorted_implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_variables(confhandler, impdict, threshold_fscore):\n",
    "    confhandler.new_section(impdict[\"discriminant\"])\n",
    "    cur_sec = confhandler.get_section(impdict[\"discriminant\"])\n",
    "\n",
    "    periodic_inputs = []\n",
    "    nonperiodic_inputs = []\n",
    "    for key, val in impdict.iteritems():\n",
    "        if val[0] > threshold_fscore and key is not \"discriminant\":\n",
    "            if \"phi\" in key or \"Phi\" in key:\n",
    "                periodic_inputs.append(key)\n",
    "            else:\n",
    "                nonperiodic_inputs.append(key)\n",
    "    cur_sec[\"nonperiodic_columns\"] = ConfigFileUtils.serialize_list(nonperiodic_inputs, lambda x: x)\n",
    "    cur_sec[\"periodic_columns\"] = ConfigFileUtils.serialize_list(periodic_inputs, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_varname(raw):\n",
    "    raw = raw.replace('(', '[')\n",
    "    raw = raw.replace(')', ']')\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "corr1 = get_feature_correlation(\"WHh1j\", [\"LepPt_0\", \"LepPt_1\"], candidate_branches, MELA_branches, list_branches, pt_limits)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_dir = \"/data_CMS/cms/wind/InputConfigurations/\"\n",
    "out_path = os.path.join(out_dir, \"exclusive_99_fullmassrange.conf\")\n",
    "threshold_fscore = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confhandler = ConfigFileHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF2j\", \"ggH2j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ggH_2j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D_VBF2j_ggH_ME', 0.06387977760718357),\n",
       " ('JetPt(JetPt|0)', 0.06278642380254496),\n",
       " ('JetPt(JetPt|1)', 0.05280666247935422),\n",
       " ('PFMET', 0.051317840277293136),\n",
       " ('ZZPt', 0.051061948961313885),\n",
       " ('JetEta(JetPt|1)', 0.04326889524740038),\n",
       " ('JetEta(JetPt|0)', 0.042803638309256285),\n",
       " ('JetPhi(JetPt|1)', 0.042780375462349085),\n",
       " ('ZZEta', 0.041873124432968103),\n",
       " ('Z1Pt', 0.04101239909740154),\n",
       " ('JetEta(JetPt|2)', 0.04066345639379347),\n",
       " ('Z2Mass', 0.0398027310582269),\n",
       " ('ZZPhi', 0.03694140088864075),\n",
       " ('JetPhi(JetPt|0)', 0.036452881103589456),\n",
       " ('ZZMass', 0.03638309256286784),\n",
       " ('D_WHh_ZHh_ME', 0.03570847000255891),\n",
       " ('ZZMassErr', 0.0356386814618373),\n",
       " ('Z2Pt', 0.0356386814618373),\n",
       " ('Z1Mass', 0.03501058459534278),\n",
       " ('D_WHh_ggH_ME', 0.02970665550050015),\n",
       " ('D_ZHh_ggH_ME', 0.029404238490706492),\n",
       " ('JetPt(JetPt|2)', 0.029055295787098426),\n",
       " ('D_VBF2j_WHh_ME', 0.02289064135668923),\n",
       " ('D_VBF2j_ZHh_ME', 0.022774327122153208),\n",
       " ('JetPhi(JetPt|2)', 0.01544653034638379),\n",
       " ('JetPhi(JetPt|3)', 0.0048386721566985366),\n",
       " ('JetPt(JetPt|3)', 0.00469909507525531),\n",
       " ('JetEta(JetPt|3)', 0.004419940912368856),\n",
       " ('Z1Flav', 0.0031637471793798124),\n",
       " ('Z2Flav', 0.0028380673226789496),\n",
       " ('nCleanedJetsPt30', 0.0026519645474213133),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.0013725079675250657),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.00034894270360806757),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.00027915416288645404),\n",
       " ('nExtraLep', 0.00013957708144322702),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.00013957708144322702)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF1j\", \"ggH1j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ggH_1j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JetEta(JetPt|0)', 0.14584154513204572),\n",
       " ('ZZEta', 0.0856873822975518),\n",
       " ('D_VBF1j_ggH_ME', 0.08505233653046029),\n",
       " ('JetPt(JetPt|0)', 0.08100118249901458),\n",
       " ('ZZPt', 0.07684053781807033),\n",
       " ('PFMET', 0.07561424254368677),\n",
       " ('Z1Pt', 0.0657162878290194),\n",
       " ('JetPhi(JetPt|0)', 0.05505189856786231),\n",
       " ('ZZMass', 0.05496430604826348),\n",
       " ('ZZMassErr', 0.05467963035956729),\n",
       " ('Z1Mass', 0.05386939955327815),\n",
       " ('ZZPhi', 0.0536942145140805),\n",
       " ('Z2Pt', 0.04979634739193273),\n",
       " ('Z2Mass', 0.04907370910524241),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.0044672184995401395),\n",
       " ('Z1Flav', 0.003021941926159506),\n",
       " ('Z2Flav', 0.002364998029168309),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.0016204616125782857),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0011168046248850349),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0003722682082950116),\n",
       " ('nExtraLep', 0.00015328690929794595)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF0j\", \"ggH0j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ggH_0j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZZPt', 0.1606582032113947),\n",
       " ('PFMET', 0.11248728270004865),\n",
       " ('ZZMass', 0.10903702393064095),\n",
       " ('ZZEta', 0.09970363161852523),\n",
       " ('Z1Pt', 0.09545715928694652),\n",
       " ('Z2Pt', 0.08966249391781307),\n",
       " ('ZZPhi', 0.08276197637899765),\n",
       " ('Z1Mass', 0.0816561242093157),\n",
       " ('Z2Mass', 0.08130225151501748),\n",
       " ('ZZMassErr', 0.07670190648914053),\n",
       " ('Z1Flav', 0.004644579112664219),\n",
       " ('Z2Flav', 0.0030963860751094794),\n",
       " ('nExtraLep', 0.0009731499093201221),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0008846817357455655),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0005308090414473393),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.00044234086787278275)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh2j\", \"ggH2j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ggH_2j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JetPt(JetPt|0)', 0.05882962195753495),\n",
       " ('JetPt(JetPt|1)', 0.05427239772138788),\n",
       " ('D_VBF2j_ggH_ME', 0.0524287933713102),\n",
       " ('ZZEta', 0.05178663904712584),\n",
       " ('PFMET', 0.04996374935266701),\n",
       " ('ZZMass', 0.04967374417400311),\n",
       " ('JetEta(JetPt|0)', 0.04859658208182289),\n",
       " ('ZZPt', 0.048513723459347485),\n",
       " ('D_WHh_ggH_ME', 0.04493008803728638),\n",
       " ('Z1Pt', 0.040932159502848266),\n",
       " ('JetEta(JetPt|2)', 0.03950284826514759),\n",
       " ('ZZPhi', 0.03554634904194718),\n",
       " ('JetEta(JetPt|1)', 0.035380631796996374),\n",
       " ('JetPhi(JetPt|0)', 0.03469704816157431),\n",
       " ('Z2Pt', 0.034137752459865355),\n",
       " ('ZZMassErr', 0.03393060590367685),\n",
       " ('D_WHh_ZHh_ME', 0.033516312791299845),\n",
       " ('Z1Mass', 0.032749870533402385),\n",
       " ('Z2Mass', 0.03250129466597618),\n",
       " ('D_ZHh_ggH_ME', 0.032128430864836875),\n",
       " ('JetPhi(JetPt|1)', 0.03132055929570171),\n",
       " ('JetPhi(JetPt|2)', 0.024919730709476954),\n",
       " ('JetPt(JetPt|2)', 0.02392542723977214),\n",
       " ('D_VBF2j_ZHh_ME', 0.022931123770067324),\n",
       " ('D_VBF2j_WHh_ME', 0.01615743138270326),\n",
       " ('JetEta(JetPt|3)', 0.009010875194199897),\n",
       " ('JetPt(JetPt|3)', 0.007291558777835319),\n",
       " ('JetPhi(JetPt|3)', 0.007063697566027965),\n",
       " ('nCleanedJetsPt30', 0.004163645779388918),\n",
       " ('Z2Flav', 0.0040186431900569655),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.0027757638529259453),\n",
       " ('Z1Flav', 0.001346452615225272),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.0009528741584671154),\n",
       " ('nExtraLep', 8.285862247540134e-05),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 2.0714655618850335e-05)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh1j\", \"ggH1j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ggH_1j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JetEta(JetPt|0)', 0.13845729267283013),\n",
       " ('ZZEta', 0.11585483648406238),\n",
       " ('JetPt(JetPt|0)', 0.09405271146681385),\n",
       " ('D_VBF1j_ggH_ME', 0.07870843107492756),\n",
       " ('ZZPt', 0.07639023044018214),\n",
       " ('PFMET', 0.0639161032151235),\n",
       " ('ZZMassErr', 0.061018352421691735),\n",
       " ('ZZMass', 0.05900372567959156),\n",
       " ('Z1Pt', 0.05362218849178971),\n",
       " ('ZZPhi', 0.053456602732165036),\n",
       " ('Z2Mass', 0.051717952256105974),\n",
       " ('Z2Pt', 0.051717952256105974),\n",
       " ('Z1Mass', 0.04570166965640955),\n",
       " ('JetPhi(JetPt|0)', 0.044404581206016286),\n",
       " ('Z2Flav', 0.004139643990616807),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.0025665792741824205),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.0020146267421001793),\n",
       " ('Z1Flav', 0.0016282599696426107),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0008831240513315855),\n",
       " ('nExtraLep', 0.0007175382917069132),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 2.7597626604112046e-05)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh0j\", \"ggH0j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ggH_0j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZZPt', 0.16273490603758498),\n",
       " ('PFMET', 0.11168865787018525),\n",
       " ('ZZMass', 0.10655737704918032),\n",
       " ('ZZEta', 0.10582433693189391),\n",
       " ('ZZMassErr', 0.09429561508729842),\n",
       " ('ZZPhi', 0.08869785419165667),\n",
       " ('Z2Mass', 0.08483273357323737),\n",
       " ('Z2Pt', 0.07963481274157004),\n",
       " ('Z1Pt', 0.07730241236838598),\n",
       " ('Z1Mass', 0.07570305211248834),\n",
       " ('Z1Flav', 0.004998000799680128),\n",
       " ('Z2Flav', 0.0035319205651072904),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0032653605224576836),\n",
       " ('nExtraLep', 0.0008663201386112222),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 6.66400106624017e-05)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh2j\", \"ggH2j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ggH_2j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JetPt(JetPt|0)', 0.0652191591445068),\n",
       " ('JetPt(JetPt|1)', 0.05354964625518419),\n",
       " ('D_ZHh_ggH_ME', 0.05139464910140685),\n",
       " ('ZZPt', 0.051110026835813616),\n",
       " ('JetEta(JetPt|0)', 0.05037814101000244),\n",
       " ('D_VBF2j_ggH_ME', 0.0499308774497845),\n",
       " ('Z1Pt', 0.04826380417988127),\n",
       " ('ZZEta', 0.046840692851915104),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.04106692689273807),\n",
       " ('ZZPhi', 0.04086362527445719),\n",
       " ('JetEta(JetPt|2)', 0.03956249491745954),\n",
       " ('JetEta(JetPt|1)', 0.03874928844433602),\n",
       " ('Z2Mass', 0.03854598682605514),\n",
       " ('JetPhi(JetPt|0)', 0.03427665284215663),\n",
       " ('PFMET', 0.03374806863462633),\n",
       " ('ZZMass', 0.033260144750752216),\n",
       " ('D_WHh_ggH_ME', 0.030617223713100758),\n",
       " ('Z1Mass', 0.03045458241847605),\n",
       " ('Z2Pt', 0.02935675367975929),\n",
       " ('D_WHh_ZHh_ME', 0.026876473936732537),\n",
       " ('D_VBF2j_WHh_ME', 0.025006099048548426),\n",
       " ('JetPhi(JetPt|2)', 0.02427421322273725),\n",
       " ('ZZMassErr', 0.023461006749613728),\n",
       " ('JetPt(JetPt|2)', 0.023379686102301376),\n",
       " ('JetPhi(JetPt|1)', 0.021712612832398146),\n",
       " ('D_VBF2j_ZHh_ME', 0.013539887777506709),\n",
       " ('JetPt(JetPt|3)', 0.012116776449540538),\n",
       " ('JetPhi(JetPt|3)', 0.008050744083922909),\n",
       " ('JetEta(JetPt|3)', 0.005814426282833211),\n",
       " ('nCleanedJetsPt30', 0.0038220704236805723),\n",
       " ('Z2Flav', 0.0028462226559323412),\n",
       " ('Z1Flav', 0.001748393917215581),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0001626412946247052)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh1j\", \"ggH1j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ggH_1j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JetEta(JetPt|0)', 0.11710013282488539),\n",
       " ('ZZEta', 0.11401516774497622),\n",
       " ('JetPt(JetPt|0)', 0.09486267620720683),\n",
       " ('D_VBF1j_ggH_ME', 0.08800719825185312),\n",
       " ('ZZPhi', 0.0754102575088907),\n",
       " ('ZZPt', 0.07112558378679464),\n",
       " ('ZZMass', 0.06559835468529071),\n",
       " ('Z2Mass', 0.056729080080551865),\n",
       " ('Z1Pt', 0.05437250953339903),\n",
       " ('PFMET', 0.05253009983289773),\n",
       " ('JetPhi(JetPt|0)', 0.048502506534127424),\n",
       " ('Z1Mass', 0.046960023994172845),\n",
       " ('ZZMassErr', 0.0463601696730794),\n",
       " ('Z2Pt', 0.04408929260036848),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.012468400531299542),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.003084965079909165),\n",
       " ('nExtraLep', 0.0026993444449205195),\n",
       " ('Z2Flav', 0.002185183598268992),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0016281760143965038),\n",
       " ('Z1Flav', 0.001242555379407858),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.001028321693303055)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh0j\", \"ggH0j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ggH_0j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZZPt', 0.14670854600183222),\n",
       " ('Z2Mass', 0.11870174060986782),\n",
       " ('ZZMassErr', 0.10914801727522576),\n",
       " ('Z2Pt', 0.10522182960345504),\n",
       " ('ZZPhi', 0.10208087946603847),\n",
       " ('Z1Mass', 0.08663787462374035),\n",
       " ('Z1Pt', 0.08624525585656327),\n",
       " ('ZZEta', 0.08297343279675436),\n",
       " ('PFMET', 0.07420494699646643),\n",
       " ('ZZMass', 0.07302709069493522),\n",
       " ('Z1Flav', 0.007852375343541421),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.004973171050909567),\n",
       " ('Z2Flav', 0.0014396021463159272),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0007852375343541421)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh2j\", \"ZHh2j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ZHh_2j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D_WHh_ZHh_ME', 0.0660503845882436),\n",
       " ('JetPhi(JetPt|1)', 0.05440688730505963),\n",
       " ('PFMET', 0.051937054548020604),\n",
       " ('ZZMass', 0.0467151224331381),\n",
       " ('Z2Mass', 0.04495095617811023),\n",
       " ('ZZMassErr', 0.04219885682026674),\n",
       " ('JetEta(JetPt|0)', 0.04219885682026674),\n",
       " ('D_WHh_ggH_ME', 0.041704890268858937),\n",
       " ('JetPt(JetPt|1)', 0.04001129066403218),\n",
       " ('Z1Mass', 0.03987015736362995),\n",
       " ('JetPt(JetPt|0)', 0.03923505751181992),\n",
       " ('Z2Pt', 0.03768259120739539),\n",
       " ('ZZEta', 0.037259191306188696),\n",
       " ('JetPhi(JetPt|0)', 0.03690635805518312),\n",
       " ('Z1Pt', 0.03669465810457977),\n",
       " ('JetEta(JetPt|1)', 0.035565591701361934),\n",
       " ('ZZPhi', 0.03168442594030062),\n",
       " ('JetPhi(JetPt|2)', 0.030978759438289465),\n",
       " ('D_ZHh_ggH_ME', 0.03076705948768612),\n",
       " ('ZZPt', 0.02780326017923929),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.027732693529038177),\n",
       " ('JetPt(JetPt|2)', 0.026533060475619222),\n",
       " ('D_VBF2j_ggH_ME', 0.025403994072401383),\n",
       " ('D_VBF2j_WHh_ME', 0.02505116082139581),\n",
       " ('D_VBF2j_ZHh_ME', 0.02194622821254675),\n",
       " ('JetEta(JetPt|2)', 0.01524239644344083),\n",
       " ('JetPhi(JetPt|3)', 0.013054830287206266),\n",
       " ('nCleanedJetsPt30', 0.010443864229765013),\n",
       " ('JetEta(JetPt|3)', 0.007621198221720415),\n",
       " ('Z1Flav', 0.0064921318185025756),\n",
       " ('JetPt(JetPt|3)', 0.004233999012066897),\n",
       " ('Z2Flav', 0.0012701997036200692),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.00035283325100557477)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh1j\", \"ZHh1j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ZHh_1j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZZMass', 0.11099712761592122),\n",
       " ('Z2Mass', 0.0883258104226508),\n",
       " ('Z2Pt', 0.08627410750923266),\n",
       " ('ZZMassErr', 0.08165777595404186),\n",
       " ('ZZPhi', 0.0720147722609766),\n",
       " ('PFMET', 0.07129667624128026),\n",
       " ('Z1Mass', 0.06955272876487485),\n",
       " ('JetPt(JetPt|0)', 0.0613459171112023),\n",
       " ('ZZPt', 0.05970455478046779),\n",
       " ('D_VBF1j_ggH_ME', 0.05857611817808781),\n",
       " ('JetPhi(JetPt|0)', 0.05642183011899877),\n",
       " ('ZZEta', 0.05365203118588428),\n",
       " ('JetEta(JetPt|0)', 0.05313910545752975),\n",
       " ('Z1Pt', 0.050984817398440706),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.018362741075092327),\n",
       " ('Z2Flav', 0.0029749692244562987),\n",
       " ('Z1Flav', 0.0025646286417726713),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.002154288059089044)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh0j\", \"ZHh0j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ZHh_0j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PFMET', 0.18597560975609756),\n",
       " ('ZZPhi', 0.1524390243902439),\n",
       " ('ZZPt', 0.1402439024390244),\n",
       " ('ZZEta', 0.125),\n",
       " ('Z1Pt', 0.11890243902439024),\n",
       " ('Z2Pt', 0.07926829268292683),\n",
       " ('Z2Mass', 0.07317073170731707),\n",
       " ('Z1Mass', 0.06402439024390244),\n",
       " ('ZZMassErr', 0.04573170731707317),\n",
       " ('nExtraLep', 0.01524390243902439)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF2j\", \"WHh2j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_WHh_2j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JetEta(JetPt|2)', 0.08227812000912617),\n",
       " ('D_VBF2j_ggH_ME', 0.07805726671229751),\n",
       " ('JetEta(JetPt|0)', 0.06202943189596167),\n",
       " ('JetPt(JetPt|2)', 0.053416609628108604),\n",
       " ('ZZMass', 0.047256445357061375),\n",
       " ('JetEta(JetPt|1)', 0.04637234770704997),\n",
       " ('ZZEta', 0.0453171343828428),\n",
       " ('D_WHh_ggH_ME', 0.04200889801505818),\n",
       " ('JetPt(JetPt|0)', 0.04121035820214465),\n",
       " ('PFMET', 0.039812913529545975),\n",
       " ('D_WHh_ZHh_ME', 0.03684690851015286),\n",
       " ('ZZPt', 0.035706137348847825),\n",
       " ('JetPt(JetPt|1)', 0.03553502167465206),\n",
       " ('Z2Mass', 0.03259753593429158),\n",
       " ('ZZPhi', 0.03171343828428017),\n",
       " ('Z1Pt', 0.031399726214921285),\n",
       " ('D_ZHh_ggH_ME', 0.03094341775039927),\n",
       " ('Z1Mass', 0.02803445128907141),\n",
       " ('Z2Pt', 0.027663700661647275),\n",
       " ('D_VBF2j_ZHh_ME', 0.02726443075519051),\n",
       " ('JetPhi(JetPt|0)', 0.022872461784166097),\n",
       " ('ZZMassErr', 0.02255874971480721),\n",
       " ('JetPhi(JetPt|1)', 0.019507186858316223),\n",
       " ('D_VBF2j_WHh_ME', 0.01691193246634725),\n",
       " ('JetPhi(JetPt|2)', 0.01676933607118412),\n",
       " ('JetEta(JetPt|3)', 0.011464750171115675),\n",
       " ('JetPt(JetPt|3)', 0.010152863335614876),\n",
       " ('JetPhi(JetPt|3)', 0.007671686059776409),\n",
       " ('nCleanedJetsPt30', 0.007129819758156514),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.003935660506502395),\n",
       " ('Z1Flav', 0.0023100616016427105),\n",
       " ('Z2Flav', 0.0021674652064795803),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.000513347022587269),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.00048482774355464294),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 8.555783709787816e-05)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF1j\", \"WHh1j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_WHh_1j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF0j\", \"WHh0j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_WHh_0j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF2j\", \"ZHh2j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ZHh_2j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF1j\", \"ZHh1j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ZHh_1j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF0j\", \"ZHh0j\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ZHh_0j_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ZHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ZHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the variable configuration\n",
    "confhandler.save_configuration(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"input_parameters_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now plot the data contained in the table to have a global picture of the relevant input variables\n",
    "datacol_labels = [col for col in df.columns.tolist() if col != \"discriminant\"]\n",
    "variable_data = df[datacol_labels].as_matrix().transpose()\n",
    "datacol_labels = np.concatenate([[''], np.array(datacol_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminant_labels = np.concatenate([[''], df[\"discriminant\"].as_matrix()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(variable_data, interpolation = 'nearest', cmap = 'Blues', vmin = np.min(variable_data), vmax = np.max(variable_data))\n",
    "ax.set_xticklabels(discriminant_labels, rotation = 'vertical')\n",
    "ax.set_yticklabels(datacol_labels)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, \"input_variables_exclusive_fullmassrange.pdf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
