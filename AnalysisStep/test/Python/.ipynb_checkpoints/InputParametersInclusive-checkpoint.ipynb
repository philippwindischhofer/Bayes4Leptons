{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainlib.FileCollection import FileCollection\n",
    "from trainlib.config import Config\n",
    "from trainlib.ConfigFileHandler import ConfigFileHandler\n",
    "from trainlib.ConfigFileUtils import ConfigFileUtils\n",
    "import trainlib.cuts as cuts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from scipy import interpolate\n",
    "import scipy.integrate as integrate\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#candidate_branches = [\"PFMET\", \"nCleanedJetsPt30\", \"nCleanedJetsPt30BTagged_bTagSF\", \"nExtraLep\", \"ZZMass\", \"nExtraZ\", \"Z1Mass\", \"Z2Mass\", \"Z1Pt\", \"Z2Pt\", \"ZZMassErr\", \"ZZPt\", \"ZZEta\", \"ZZPhi\", \"Z1Flav\", \"Z2Flav\", \"costhetastar\", \"helphi\", \"helcosthetaZ1\", \"helcosthetaZ2\", \"phistarZ1\", \"phistarZ2\", \"xi\", \"xistar\"]\n",
    "candidate_branches = [\"PFMET\", \"nCleanedJetsPt30\", \"nCleanedJetsPt30BTagged_bTagSF\", \"nExtraLep\", \"ZZMass_masked\", \"nExtraZ\", \"Z1Mass\", \"Z2Mass\", \"Z1Pt\", \"Z2Pt\", \"ZZMassErr\", \"ZZPt\", \"ZZEta\", \"ZZPhi\", \"Z1Flav\", \"Z2Flav\", \"D_VBF2j_ggH_ME\", \"D_VBF1j_ggH_ME\", \"D_WHh_ggH_ME\", \"D_ZHh_ggH_ME\", \"D_WHh_ZHh_ME\", \"D_VBF2j_WHh_ME\", \"D_VBF2j_ZHh_ME\"]\n",
    "#list_branches = [\"Jet\", \"Lep\", \"ExtraLep\"]\n",
    "MELA_branches = []\n",
    "list_branches = [\"Jet\", \"ExtraLep\"]\n",
    "pt_limits = [30.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allbranches = [\"JetPt\", \"JetEta\", \"JetPhi\", \"LepPt\", \"LepEta\", \"LepPhi\", \"ExtraLepPt\", \"ExtraLepEta\", \"ExtraLepPhi\"] + candidate_branches + MELA_branches + [\"LHEAssociatedParticleId\", \"GenAssocLep1Id\", \"GenAssocLep2Id\", \"training_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MC_path = \"/data_CMS/cms/wind/CJLST_NTuples_randomizeda/\"\n",
    "MC_path = \"/data_CMS/cms/wind/CJLST_NTuples_ZZMask/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def WHhadr0j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def WHhadr01j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def WHhadr1j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def WHhadr2j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def ZHhadr0j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def ZHhadr01j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def ZHhadr1j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def ZHhadr2j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def mZZ0j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def mZZ01j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def mZZ1j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def mZZ2j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the cuts without any m4l restriction imposed\n",
    "def WHhadr0j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def WHhadr01j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def WHhadr1j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def WHhadr2j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def ZHhadr0j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def ZHhadr01j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def ZHhadr1j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def ZHhadr2j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def mZZ0j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def mZZ01j_cut(row):\n",
    "    return (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def mZZ1j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def mZZ2j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] >= 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "collections = {\"VBF2j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"VBF1j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"VBF0j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"VBF01j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"VBF\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": cuts.mZZ_cut},\n",
    "            \"ggH2j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"ggH1j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"ggH0j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"ggH01j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"ggH\" : {MC_path + \"ggH125/ZZ4lAnalysis.root\": cuts.mZZ_cut},\n",
    "            \"WHh2j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr2j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr2j_cut},\n",
    "            \"WHh1j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr1j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr1j_cut},\n",
    "            \"WHh0j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr0j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr0j_cut},\n",
    "            \"WHh\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut},\n",
    "            \"WHh01j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr01j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr01j_cut},\n",
    "            \"WHl\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut},\n",
    "            \"ZHh2j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr2j_cut},\n",
    "            \"ZHh1j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr1j_cut},\n",
    "            \"ZHh01j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr01j_cut},\n",
    "            \"ZHh0j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr0j_cut},\n",
    "            \"ZHh\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHhadr_cut},\n",
    "            \"ZHl\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHlept_cut},\n",
    "            \"ttHh\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHhadr_cut},\n",
    "            \"ttHl\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHlept_cut},\n",
    "            \"ZHMET\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHMET_cut}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collections = {\"VBF2j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"VBF1j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"VBF0j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"VBF01j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"VBF\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": cuts.no_cut},\n",
    "            \"ggH2j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"ggH1j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"ggH0j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"ggH01j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"ggH\" : {MC_path + \"ggH125/ZZ4lAnalysis.root\": cuts.no_cut},\n",
    "            \"WHh2j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr2j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr2j_cut},\n",
    "            \"WHh1j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr1j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr1j_cut},\n",
    "            \"WHh0j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr0j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr0j_cut},\n",
    "            \"WHh\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut},\n",
    "            \"WHh01j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr01j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr01j_cut},\n",
    "            \"WHl\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut},\n",
    "            \"ZHh2j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr2j_cut},\n",
    "            \"ZHh1j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr1j_cut},\n",
    "            \"ZHh01j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr01j_cut},\n",
    "            \"ZHh0j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr0j_cut},\n",
    "            \"ZHh\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHhadr_cut},\n",
    "            \"ZHl\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHlept_cut},\n",
    "            \"ttHh\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHhadr_cut},\n",
    "            \"ttHl\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHlept_cut},\n",
    "            \"ZHMET\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHMET_cut}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all the model combinations for which neural networks are currently trained\n",
    "discriminant_pairs = [(\"VBF\", \"ggH\"), (\"WHh\", \"ggH\"), (\"ZHh\", \"ggH\"), (\"WHh\", \"ZHh\"), (\"VBF\", \"WHh\"),\n",
    "                     (\"VBF\", \"ZHh\"), (\"WHl\", \"ggH\"), (\"WHl\", \"VBF\"), (\"WHl\", \"WHh\"), (\"WHl\", \"ZHh\"),\n",
    "                     (\"WHl\", \"ZHl\"), (\"WHl\", \"ZHMET\"), (\"WHl\", \"ttHh\"), (\"WHl\", \"ttHl\"), (\"ZHh\", \"ZHl\"),\n",
    "                     (\"ZHh\", \"ZHMET\"), (\"ZHh\", \"ttHh\"), (\"ZHh\", \"ttHl\"), (\"ZHl\", \"ggH\"), (\"ZHl\", \"VBF\"),\n",
    "                     (\"ZHl\", \"WHh\"), (\"ZHl\", \"ZHMET\"), (\"ZHl\", \"ttHh\"), (\"ZHl\", \"ttHl\"), (\"ZHMET\", \"ggH\"),\n",
    "                     (\"ZHMET\", \"VBF\"), (\"ZHMET\", \"WHh\"), (\"ZHMET\", \"ttHh\"), (\"ZHMET\", \"ttHl\"), (\"ttHh\", \"ggH\"),\n",
    "                      (\"ttHh\", \"VBF\"), (\"ttHh\", \"WHh\"), (\"ttHh\", \"ttHl\"), (\"ttHl\", \"ggH\"), (\"ttHl\", \"VBF\"),\n",
    "                     (\"ttHl\", \"WHh\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_order(df, col_basename, sorted_column, columns, order):\n",
    "    def get_index(row, order, col_basename, sorted_column):\n",
    "        sorted_column = row[col_basename + sorted_column]\n",
    "        if order >= len(sorted_column):\n",
    "            return -1\n",
    "        else:\n",
    "            return np.flipud(np.argsort(sorted_column))[order]\n",
    "    \n",
    "    index_column = pd.DataFrame(df.transform(lambda row: get_index(row, order, col_basename, sorted_column), axis = 1, raw = True))\n",
    "    index_column.columns = [\"index\"]\n",
    "    df_temp = pd.concat([index_column, df], axis = 1)\n",
    "    \n",
    "    def get_element(row, column_name):\n",
    "        if row[\"index\"] == -1:\n",
    "            return 0\n",
    "        else:\n",
    "            return row[column_name][row[\"index\"]]\n",
    "        \n",
    "    extracted_cols = pd.DataFrame()\n",
    "    for column in columns:\n",
    "        extracted_col = pd.DataFrame(df_temp.transform(lambda row: get_element(row, col_basename + column), axis = 1, raw = True))\n",
    "        extracted_col.columns = [col_basename + column + \"(\" + col_basename + \"Pt|\" + str(order) + \")\"]\n",
    "        extracted_cols = pd.concat([extracted_cols, extracted_col], axis = 1)\n",
    "        \n",
    "    return extracted_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, col_basenames, sorted_column, columns, orders, pt_limits):\n",
    "    all_extracted = pd.DataFrame()\n",
    "    for col_basename, pt_limit in zip(col_basenames, pt_limits):\n",
    "        for order in orders:\n",
    "            extracted = extract_order(df, col_basename, sorted_column, columns, order)\n",
    "            mask = extracted[col_basename + \"Pt(\" + col_basename + \"Pt|\" + str(order) + \")\"] < pt_limit\n",
    "            extracted[mask] = 0.0\n",
    "\n",
    "            all_extracted = pd.concat([all_extracted, extracted], axis = 1)\n",
    "            \n",
    "    return all_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits):\n",
    "    H1_df = H1_coll.get_data(read_branches, 0.0, 1.0)\n",
    "    H0_df = H0_coll.get_data(read_branches, 0.0, 1.0)\n",
    "    \n",
    "    H1_list_df = prepare_data(H1_df, list_branches, \"Pt\", [\"Pt\", \"Eta\", \"Phi\"], range(4), pt_limits)\n",
    "    H0_list_df = prepare_data(H0_df, list_branches, \"Pt\", [\"Pt\", \"Eta\", \"Phi\"], range(4), pt_limits)\n",
    "    \n",
    "    list_branches_unrolled = H1_list_df.columns\n",
    "            \n",
    "    H1_df = pd.concat([H1_df, H1_list_df], axis = 1)\n",
    "    H0_df = pd.concat([H0_df, H0_list_df], axis = 1)        \n",
    "    \n",
    "    complete_input_branches = np.concatenate([input_branches, list_branches_unrolled])\n",
    "            \n",
    "    H1_df = H1_df[complete_input_branches]\n",
    "    H0_df = H0_df[complete_input_branches]\n",
    "    \n",
    "    return H1_df, H0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_dmatrix(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits):\n",
    "    H1_df, H0_df = get_data(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    complete_input_branches = H1_df.columns\n",
    "    print \"number of input variables: \" + str(len(complete_input_branches))\n",
    "    print \"final list of inputs: \" + str(complete_input_branches)\n",
    "    \n",
    "    # try with the same weights as used later in the neural network training, to balance out some (very)\n",
    "    # unbalanced datasets\n",
    "    H1_class_weight = 1.0 + float(len(H0_df)) / float(len(H1_df))\n",
    "    H0_class_weight = 1.0 + float(len(H1_df)) / float(len(H0_df))\n",
    "    \n",
    "    print \"using class weights: \" + str(H1_class_weight) + \" (H1), \" + str(H0_class_weight) + \" (H0)\"\n",
    "    \n",
    "    H1_weights = np.full(len(H1_df), H1_class_weight)\n",
    "    H0_weights = np.full(len(H0_df), H0_class_weight)\n",
    "    \n",
    "    H1_data = H1_df.as_matrix()\n",
    "    H0_data = H0_df.as_matrix()\n",
    "    H1_target = np.ones(np.shape(H1_data)[0])\n",
    "    H0_target = np.zeros(np.shape(H0_data)[0])\n",
    "    \n",
    "    target = np.concatenate([H1_target, H0_target])\n",
    "    data = np.concatenate([H1_data, H0_data])\n",
    "    weights = np.concatenate([H1_weights, H0_weights])\n",
    "    \n",
    "    dmatrix = xgb.DMatrix(data, label = target, feature_names = complete_input_branches, weight = weights)\n",
    "    \n",
    "    return dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_correlation(source, corr_branches, mandatory_branches, optional_branches, list_branches, pt_limits):    \n",
    "    coll = FileCollection(collections[source], 0.0, 0.5)\n",
    "    \n",
    "    input_branches = [branch for branch in mandatory_branches]\n",
    "    \n",
    "    for optional_branch in optional_branches:\n",
    "        if \"0j\" in source and (\"0j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        if \"1j\" in source and (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        if \"2j\" in source and (\"2j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "\n",
    "    df, _ = get_data(coll, coll, allbranches, input_branches, list_branches, pt_limits)\n",
    "\n",
    "    df = df[corr_branches]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    cax = ax.matshow(df.corr(), vmin = -1.0, vmax = 1.0, cmap = \"RdBu\")\n",
    "    \n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    ax.set_yticklabels([''] + corr_branches)\n",
    "    ax.set_xticklabels([''] + corr_branches, rotation = 'vertical')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interpolating_function(data, bins):\n",
    "    bin_centers = [np.mean([bins[i], bins[i + 1]]) for i in range(len(bins) - 1)]\n",
    "    intf = interpolate.interp1d(bin_centers, data, kind = \"linear\")\n",
    "    interpolated_function = lambda x: intf(x) if x > bin_centers[0] and x < bin_centers[-1] else 0\n",
    "    \n",
    "    return interpolated_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binned_data(df, branch):\n",
    "    data = df[branch].as_matrix()\n",
    "    weights = df[\"training_weight\"].as_matrix()\n",
    "    \n",
    "    # set the bin width\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    bin_width = max(2 * (q75 - q25) / len(data)**0.33, 0.005)\n",
    "\n",
    "    data_max = np.max(data)\n",
    "    data_min = np.min(data)\n",
    "    bins = np.arange(data_min, data_max + bin_width, bin_width)\n",
    "    \n",
    "    weights = weights / (np.sum(weights) * bin_width)\n",
    "    \n",
    "    hist = np.histogram(data, bins = bins, weights = weights)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_list_BDT(disc_pair, mandatory_branches, optional_branches, list_branches, pt_limits):\n",
    "    H1_name = disc_pair[0]\n",
    "    H0_name = disc_pair[1]\n",
    "    \n",
    "    # first assemble the list of branches that can serve as input: it will *always* contain the mandatory branches,\n",
    "    # and *can* contain some of the optional branches, if the name of the categories allows it\n",
    "    input_branches = [branch for branch in mandatory_branches]\n",
    "    \n",
    "    for optional_branch in optional_branches:\n",
    "        if (\"0j\" in H1_name or \"0j\" in H0_name) and (\"0j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)  \n",
    "        elif (\"1j\" in H1_name or \"1j\" in H0_name) and (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "        elif (\"2j\" in H1_name or \"2j\" in H0_name) and not (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        # the fully inclusive categories (i.e. those with NO \"xxj\" in their name, can not use MELA, since there may\n",
    "        # be events with low number of jets contained)\n",
    "    \n",
    "    # get the training data for the BDT ...\n",
    "    H1_coll_train = FileCollection(collections[H1_name], 0.0, 0.5)\n",
    "    H0_coll_train = FileCollection(collections[H0_name], 0.0, 0.5)\n",
    "    \n",
    "    dtrain = get_data_dmatrix(H1_coll_train, H0_coll_train, allbranches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    # ... and the validation data as well\n",
    "    H1_coll_val = FileCollection(collections[H1_name], 0.5, 1.0)\n",
    "    H0_coll_val = FileCollection(collections[H0_name], 0.5, 1.0)\n",
    "    dval = get_data_dmatrix(H1_coll_val, H0_coll_val, allbranches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "    \n",
    "    # perform the training\n",
    "    # try different tree depths and choose the one that gives the best RMSE (i.e. avoid too deep trees to start with)\n",
    "        \n",
    "    params = {'eta': 0.01, 'silent': 1, 'gamma': 0.5, 'objective': 'binary:logistic'}\n",
    "    params['nthread'] = 4\n",
    "    params['eval_metric'] = 'rmse'\n",
    "    max_num_rounds = 2000\n",
    "    \n",
    "    best_loss = 1e6\n",
    "    best_imp = None\n",
    "    best_params = None\n",
    "    for tree_depth in range(1,8):\n",
    "        params['max_depth'] = tree_depth\n",
    "        \n",
    "        bst = xgb.train(params, dtrain, max_num_rounds, evals = evallist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "    \n",
    "        pred = bst.predict(dval)\n",
    "        cur_loss = np.sqrt(mean_squared_error(pred, dval.get_label()))\n",
    "        cur_imp = bst.get_fscore()\n",
    "\n",
    "        print \"for max_depth = \" + str(params['max_depth']) + \": loss = \" + str(cur_loss)\n",
    "        \n",
    "        if cur_loss < best_loss:\n",
    "            best_loss = cur_loss\n",
    "            best_imp = copy.copy(cur_imp)\n",
    "            best_params = copy.copy(params)\n",
    "            \n",
    "    # normalize the usage score w.r.t. the total score (i.e. sum of all individuals)\n",
    "    score_sum = sum([val for key, val in best_imp.iteritems()])\n",
    "    used_variables = {key: val / float(score_sum) for key, val in sorted(best_imp.iteritems(), key = lambda x: x[1], reverse = True)}           \n",
    "    return best_params, dtrain.feature_names, used_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_histogram(df, branch, label):\n",
    "    data = df[branch].as_matrix()\n",
    "    weights = df[\"training_weight\"].as_matrix()\n",
    "    \n",
    "    # set the bin width\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    bin_width = max(2 * (q75 - q25) / len(data)**0.33, 0.005)\n",
    "\n",
    "    data_max = np.max(data)\n",
    "    data_min = np.min(data)\n",
    "    bins = np.arange(data_min, data_max + bin_width, bin_width)\n",
    "    \n",
    "    weights = weights / (np.sum(weights) * bin_width)\n",
    "    \n",
    "    fig = plt.hist(data, bins = bins, weights = weights, alpha = 0.5, label = label)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_branch(disc_pair, branch, start_fraction = 0.0, end_fraction = 1.0):\n",
    "    H1_name = disc_pair[0]\n",
    "    H0_name = disc_pair[1]\n",
    "    \n",
    "    # get the training data for the BDT ...\n",
    "    H1_coll = FileCollection(collections[H1_name], start_fraction, end_fraction)\n",
    "    H0_coll = FileCollection(collections[H0_name], start_fraction, end_fraction)\n",
    "    \n",
    "    H1_df, H0_df = get_data(H1_coll, H0_coll, allbranches, allbranches, list_branches, pt_limits)\n",
    "    \n",
    "    plt.figure()\n",
    "    H1_hist = get_histogram(H1_df, branch, H1_name)\n",
    "    H0_hist = get_histogram(H0_df, branch, H0_name)\n",
    "    \n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_variables(discs):\n",
    "    plotframe = pd.DataFrame()\n",
    "    \n",
    "    for disc in discs:\n",
    "        _, _, implist = get_feature_importance_list_BDT(disc, candidate_branches, MELA_branches, list_branches, pt_limits)\n",
    "        \n",
    "        # cut the list to select only the 95% most important variables\n",
    "        cutimplist = {key: val for key, val in implist.iteritems() if val > 0.00}\n",
    "        curframe = pd.DataFrame(cutimplist, index = [len(plotframe)])\n",
    "        \n",
    "        plotframe = pd.concat([plotframe, curframe])\n",
    "        \n",
    "    plotframe = plotframe.fillna(0.0)\n",
    "    \n",
    "    print plotframe\n",
    "    print \"number of pre-selected input variables = \" + str(len(plotframe.columns))\n",
    "    \n",
    "    # start the plotting\n",
    "    parameters = plotframe.columns\n",
    "    plotdata = np.transpose(plotframe.as_matrix())\n",
    "    \n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize=(10,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(plotdata, cmap = 'Blues')\n",
    "    \n",
    "    # make axis labels\n",
    "    disclabels = []\n",
    "    for disc in discs:\n",
    "        if \"0j\" in disc[0] or \"0j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('0j', '', disc[0]) + \"_\" + re.sub('0j', '', disc[1]) + \"_0j\")\n",
    "        elif \"01j\" in disc[0] or \"01j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('01j', '', disc[0]) + \"_\" + re.sub('01j', '', disc[1]) + \"_01j\")\n",
    "        elif \"1j\" in disc[0] or \"1j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('1j', '', disc[0]) + \"_\" + re.sub('1j', '', disc[1]) + \"_1j\")\n",
    "        elif \"2j\" in disc[0] or \"2j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('2j', '', disc[0]) + \"_\" + re.sub('2j', '', disc[1]) + \"_2j\")\n",
    "        else:\n",
    "            disclabels.append('D_' + disc[0] + \"_\" + disc[1] + \"_2j\")\n",
    "            \n",
    "    disclabels = np.concatenate([[''], np.array(disclabels)])\n",
    "    parameters = np.concatenate([[''], np.array(parameters)])\n",
    "        \n",
    "    ax.set_xticklabels(disclabels, rotation = 'vertical')\n",
    "    ax.set_yticklabels(parameters)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    # sort the used variables according to their importance\n",
    "    sorted_implist = []\n",
    "    for key, val in sorted(cutimplist.iteritems(), key = lambda x: x[1], reverse = True):\n",
    "        sorted_implist.append((key, val))\n",
    "    \n",
    "    return fig, sorted_implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_variables(confhandler, impdict, threshold_fscore):\n",
    "    confhandler.new_section(impdict[\"discriminant\"])\n",
    "    cur_sec = confhandler.get_section(impdict[\"discriminant\"])\n",
    "\n",
    "    periodic_inputs = []\n",
    "    nonperiodic_inputs = []\n",
    "    for key, val in impdict.iteritems():\n",
    "        if val[0] > threshold_fscore and key is not \"discriminant\":\n",
    "            if \"phi\" in key or \"Phi\" in key:\n",
    "                periodic_inputs.append(key)\n",
    "            else:\n",
    "                nonperiodic_inputs.append(key)\n",
    "    cur_sec[\"nonperiodic_columns\"] = ConfigFileUtils.serialize_list(nonperiodic_inputs, lambda x: x)\n",
    "    cur_sec[\"periodic_columns\"] = ConfigFileUtils.serialize_list(periodic_inputs, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_varname(raw):\n",
    "    raw = raw.replace('(', '[')\n",
    "    raw = raw.replace(')', ']')\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_dir = \"/data_CMS/cms/wind/InputConfigurations/\"\n",
    "out_path = os.path.join(out_dir, \"inclusive_99_fullmassrange_ZZMask.conf\")\n",
    "threshold_fscore = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confhandler = ConfigFileHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh\", \"ZHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ZHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF\", \"ZHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ZHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ZHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ZHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the variable configuration\n",
    "confhandler.save_configuration(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"input_parameters_table_inclusive_ZZMask.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now plot the data contained in the table to have a global picture of the relevant input variables\n",
    "datacol_labels = [col for col in df.columns.tolist() if col != \"discriminant\"]\n",
    "variable_data = df[datacol_labels].as_matrix().transpose()\n",
    "datacol_labels = np.concatenate([[''], np.array(datacol_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminant_labels = np.concatenate([[''], df[\"discriminant\"].as_matrix()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(variable_data, interpolation = 'nearest', cmap = 'Blues', vmin = np.min(variable_data), vmax = np.max(variable_data))\n",
    "ax.set_xticklabels(discriminant_labels, rotation = 'vertical')\n",
    "ax.set_yticklabels(datacol_labels)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, \"input_variables_inclusive_fullmassrange_ZZMask.pdf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
