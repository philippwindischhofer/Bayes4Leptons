{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/09\n"
     ]
    }
   ],
   "source": [
    "from trainlib.FileCollection import FileCollection\n",
    "from trainlib.config import Config\n",
    "from trainlib.ConfigFileHandler import ConfigFileHandler\n",
    "from trainlib.ConfigFileUtils import ConfigFileUtils\n",
    "import trainlib.cuts as cuts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from scipy import interpolate\n",
    "import scipy.integrate as integrate\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs_depscipy/3.0-fmblme3/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#candidate_branches = [\"PFMET\", \"nCleanedJetsPt30\", \"nCleanedJetsPt30BTagged_bTagSF\", \"nExtraLep\", \"ZZMass\", \"nExtraZ\", \"Z1Mass\", \"Z2Mass\", \"Z1Pt\", \"Z2Pt\", \"ZZMassErr\", \"ZZPt\", \"ZZEta\", \"ZZPhi\", \"Z1Flav\", \"Z2Flav\", \"costhetastar\", \"helphi\", \"helcosthetaZ1\", \"helcosthetaZ2\", \"phistarZ1\", \"phistarZ2\", \"xi\", \"xistar\"]\n",
    "candidate_branches = [\"PFMET\", \"nCleanedJetsPt30\", \"nCleanedJetsPt30BTagged_bTagSF\", \"nExtraLep\", \"ZZMass\", \"nExtraZ\", \"Z1Mass\", \"Z2Mass\", \"Z1Pt\", \"Z2Pt\", \"ZZMassErr\", \"ZZPt\", \"ZZEta\", \"ZZPhi\", \"Z1Flav\", \"Z2Flav\", \"D_VBF2j_ggH_ME\", \"D_VBF1j_ggH_ME\", \"D_WHh_ggH_ME\", \"D_ZHh_ggH_ME\", \"D_WHh_ZHh_ME\", \"D_VBF2j_WHh_ME\", \"D_VBF2j_ZHh_ME\"]\n",
    "#list_branches = [\"Jet\", \"Lep\", \"ExtraLep\"]\n",
    "MELA_branches = []\n",
    "list_branches = [\"Jet\", \"ExtraLep\"]\n",
    "pt_limits = [30.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allbranches = [\"JetPt\", \"JetEta\", \"JetPhi\", \"LepPt\", \"LepEta\", \"LepPhi\", \"ExtraLepPt\", \"ExtraLepEta\", \"ExtraLepPhi\"] + candidate_branches + MELA_branches + [\"LHEAssociatedParticleId\", \"GenAssocLep1Id\", \"GenAssocLep2Id\", \"training_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MC_path = \"/data_CMS/cms/wind/CJLST_NTuples_randomizeda/\"\n",
    "MC_path = \"/data_CMS/cms/wind/CJLST_NTuples/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def WHhadr0j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def WHhadr01j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def WHhadr1j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def WHhadr2j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def ZHhadr0j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def ZHhadr01j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def ZHhadr1j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def ZHhadr2j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def mZZ0j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def mZZ01j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def mZZ1j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def mZZ2j_cut(row):\n",
    "    return cuts.mZZ_cut(row) and row[\"nCleanedJetsPt30\"] >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the cuts without any m4l restriction imposed\n",
    "def WHhadr0j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def WHhadr01j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def WHhadr1j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def WHhadr2j_cut(row):\n",
    "    return cuts.WHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def ZHhadr0j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def ZHhadr01j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def ZHhadr1j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def ZHhadr2j_cut(row):\n",
    "    return cuts.ZHhadr_cut(row) and row[\"nCleanedJetsPt30\"] >= 2\n",
    "\n",
    "def mZZ0j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] == 0\n",
    "\n",
    "def mZZ01j_cut(row):\n",
    "    return (row[\"nCleanedJetsPt30\"] == 0 or row[\"nCleanedJetsPt30\"] == 1)\n",
    "\n",
    "def mZZ1j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] == 1\n",
    "\n",
    "def mZZ2j_cut(row):\n",
    "    return row[\"nCleanedJetsPt30\"] >= 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "collections = {\"VBF2j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"VBF1j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"VBF0j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"VBF01j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"VBF\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": cuts.mZZ_cut},\n",
    "            \"ggH2j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"ggH1j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"ggH0j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"ggH01j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"ggH\" : {MC_path + \"ggH125/ZZ4lAnalysis.root\": cuts.mZZ_cut},\n",
    "            \"WHh2j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr2j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr2j_cut},\n",
    "            \"WHh1j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr1j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr1j_cut},\n",
    "            \"WHh0j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr0j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr0j_cut},\n",
    "            \"WHh\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut},\n",
    "            \"WHh01j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr01j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr01j_cut},\n",
    "            \"WHl\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut},\n",
    "            \"ZHh2j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr2j_cut},\n",
    "            \"ZHh1j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr1j_cut},\n",
    "            \"ZHh01j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr01j_cut},\n",
    "            \"ZHh0j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr0j_cut},\n",
    "            \"ZHh\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHhadr_cut},\n",
    "            \"ZHl\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHlept_cut},\n",
    "            \"ttHh\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHhadr_cut},\n",
    "            \"ttHl\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHlept_cut},\n",
    "            \"ZHMET\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHMET_cut}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collections = {\"VBF2j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"VBF1j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"VBF0j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"VBF01j\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"VBF\": {MC_path + \"VBFH125/ZZ4lAnalysis.root\": cuts.no_cut},\n",
    "            \"ggH2j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ2j_cut},\n",
    "            \"ggH1j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ1j_cut},\n",
    "            \"ggH0j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ0j_cut},\n",
    "            \"ggH01j\": {MC_path + \"ggH125/ZZ4lAnalysis.root\": mZZ01j_cut},\n",
    "            \"ggH\" : {MC_path + \"ggH125/ZZ4lAnalysis.root\": cuts.no_cut},\n",
    "            \"WHh2j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr2j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr2j_cut},\n",
    "            \"WHh1j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr1j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr1j_cut},\n",
    "            \"WHh0j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr0j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr0j_cut},\n",
    "            \"WHh\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHhadr_cut},\n",
    "            \"WHh01j\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": WHhadr01j_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": WHhadr01j_cut},\n",
    "            \"WHl\": {MC_path + \"WplusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut, MC_path + \"WminusH125/ZZ4lAnalysis.root\": cuts.WHlept_cut},\n",
    "            \"ZHh2j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr2j_cut},\n",
    "            \"ZHh1j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr1j_cut},\n",
    "            \"ZHh01j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr01j_cut},\n",
    "            \"ZHh0j\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": ZHhadr0j_cut},\n",
    "            \"ZHh\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHhadr_cut},\n",
    "            \"ZHl\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHlept_cut},\n",
    "            \"ttHh\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHhadr_cut},\n",
    "            \"ttHl\": {MC_path + \"ttH125/ZZ4lAnalysis.root\": cuts.ttHlept_cut},\n",
    "            \"ZHMET\": {MC_path + \"ZH125/ZZ4lAnalysis.root\": cuts.ZHMET_cut}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all the model combinations for which neural networks are currently trained\n",
    "discriminant_pairs = [(\"VBF\", \"ggH\"), (\"WHh\", \"ggH\"), (\"ZHh\", \"ggH\"), (\"WHh\", \"ZHh\"), (\"VBF\", \"WHh\"),\n",
    "                     (\"VBF\", \"ZHh\"), (\"WHl\", \"ggH\"), (\"WHl\", \"VBF\"), (\"WHl\", \"WHh\"), (\"WHl\", \"ZHh\"),\n",
    "                     (\"WHl\", \"ZHl\"), (\"WHl\", \"ZHMET\"), (\"WHl\", \"ttHh\"), (\"WHl\", \"ttHl\"), (\"ZHh\", \"ZHl\"),\n",
    "                     (\"ZHh\", \"ZHMET\"), (\"ZHh\", \"ttHh\"), (\"ZHh\", \"ttHl\"), (\"ZHl\", \"ggH\"), (\"ZHl\", \"VBF\"),\n",
    "                     (\"ZHl\", \"WHh\"), (\"ZHl\", \"ZHMET\"), (\"ZHl\", \"ttHh\"), (\"ZHl\", \"ttHl\"), (\"ZHMET\", \"ggH\"),\n",
    "                     (\"ZHMET\", \"VBF\"), (\"ZHMET\", \"WHh\"), (\"ZHMET\", \"ttHh\"), (\"ZHMET\", \"ttHl\"), (\"ttHh\", \"ggH\"),\n",
    "                      (\"ttHh\", \"VBF\"), (\"ttHh\", \"WHh\"), (\"ttHh\", \"ttHl\"), (\"ttHl\", \"ggH\"), (\"ttHl\", \"VBF\"),\n",
    "                     (\"ttHl\", \"WHh\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_order(df, col_basename, sorted_column, columns, order):\n",
    "    def get_index(row, order, col_basename, sorted_column):\n",
    "        sorted_column = row[col_basename + sorted_column]\n",
    "        if order >= len(sorted_column):\n",
    "            return -1\n",
    "        else:\n",
    "            return np.flipud(np.argsort(sorted_column))[order]\n",
    "    \n",
    "    index_column = pd.DataFrame(df.transform(lambda row: get_index(row, order, col_basename, sorted_column), axis = 1, raw = True))\n",
    "    index_column.columns = [\"index\"]\n",
    "    df_temp = pd.concat([index_column, df], axis = 1)\n",
    "    \n",
    "    def get_element(row, column_name):\n",
    "        if row[\"index\"] == -1:\n",
    "            return 0\n",
    "        else:\n",
    "            return row[column_name][row[\"index\"]]\n",
    "        \n",
    "    extracted_cols = pd.DataFrame()\n",
    "    for column in columns:\n",
    "        extracted_col = pd.DataFrame(df_temp.transform(lambda row: get_element(row, col_basename + column), axis = 1, raw = True))\n",
    "        extracted_col.columns = [col_basename + column + \"(\" + col_basename + \"Pt|\" + str(order) + \")\"]\n",
    "        extracted_cols = pd.concat([extracted_cols, extracted_col], axis = 1)\n",
    "        \n",
    "    return extracted_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, col_basenames, sorted_column, columns, orders, pt_limits):\n",
    "    all_extracted = pd.DataFrame()\n",
    "    for col_basename, pt_limit in zip(col_basenames, pt_limits):\n",
    "        for order in orders:\n",
    "            extracted = extract_order(df, col_basename, sorted_column, columns, order)\n",
    "            mask = extracted[col_basename + \"Pt(\" + col_basename + \"Pt|\" + str(order) + \")\"] < pt_limit\n",
    "            extracted[mask] = 0.0\n",
    "\n",
    "            all_extracted = pd.concat([all_extracted, extracted], axis = 1)\n",
    "            \n",
    "    return all_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits):\n",
    "    H1_df = H1_coll.get_data(read_branches, 0.0, 1.0)\n",
    "    H0_df = H0_coll.get_data(read_branches, 0.0, 1.0)\n",
    "    \n",
    "    H1_list_df = prepare_data(H1_df, list_branches, \"Pt\", [\"Pt\", \"Eta\", \"Phi\"], range(4), pt_limits)\n",
    "    H0_list_df = prepare_data(H0_df, list_branches, \"Pt\", [\"Pt\", \"Eta\", \"Phi\"], range(4), pt_limits)\n",
    "    \n",
    "    list_branches_unrolled = H1_list_df.columns\n",
    "            \n",
    "    H1_df = pd.concat([H1_df, H1_list_df], axis = 1)\n",
    "    H0_df = pd.concat([H0_df, H0_list_df], axis = 1)        \n",
    "    \n",
    "    complete_input_branches = np.concatenate([input_branches, list_branches_unrolled])\n",
    "            \n",
    "    H1_df = H1_df[complete_input_branches]\n",
    "    H0_df = H0_df[complete_input_branches]\n",
    "    \n",
    "    return H1_df, H0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_dmatrix(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits):\n",
    "    H1_df, H0_df = get_data(H1_coll, H0_coll, read_branches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    complete_input_branches = H1_df.columns\n",
    "    print \"number of input variables: \" + str(len(complete_input_branches))\n",
    "    print \"final list of inputs: \" + str(complete_input_branches)\n",
    "    \n",
    "    # try with the same weights as used later in the neural network training, to balance out some (very)\n",
    "    # unbalanced datasets\n",
    "    H1_class_weight = 1.0 + float(len(H0_df)) / float(len(H1_df))\n",
    "    H0_class_weight = 1.0 + float(len(H1_df)) / float(len(H0_df))\n",
    "    \n",
    "    print \"using class weights: \" + str(H1_class_weight) + \" (H1), \" + str(H0_class_weight) + \" (H0)\"\n",
    "    \n",
    "    H1_weights = np.full(len(H1_df), H1_class_weight)\n",
    "    H0_weights = np.full(len(H0_df), H0_class_weight)\n",
    "    \n",
    "    H1_data = H1_df.as_matrix()\n",
    "    H0_data = H0_df.as_matrix()\n",
    "    H1_target = np.ones(np.shape(H1_data)[0])\n",
    "    H0_target = np.zeros(np.shape(H0_data)[0])\n",
    "    \n",
    "    target = np.concatenate([H1_target, H0_target])\n",
    "    data = np.concatenate([H1_data, H0_data])\n",
    "    weights = np.concatenate([H1_weights, H0_weights])\n",
    "    \n",
    "    dmatrix = xgb.DMatrix(data, label = target, feature_names = complete_input_branches, weight = weights)\n",
    "    \n",
    "    return dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_correlation(source, corr_branches, mandatory_branches, optional_branches, list_branches, pt_limits):    \n",
    "    coll = FileCollection(collections[source], 0.0, 0.5)\n",
    "    \n",
    "    input_branches = [branch for branch in mandatory_branches]\n",
    "    \n",
    "    for optional_branch in optional_branches:\n",
    "        if \"0j\" in source and (\"0j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        if \"1j\" in source and (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        if \"2j\" in source and (\"2j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "\n",
    "    df, _ = get_data(coll, coll, allbranches, input_branches, list_branches, pt_limits)\n",
    "\n",
    "    df = df[corr_branches]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    cax = ax.matshow(df.corr(), vmin = -1.0, vmax = 1.0, cmap = \"RdBu\")\n",
    "    \n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    ax.set_yticklabels([''] + corr_branches)\n",
    "    ax.set_xticklabels([''] + corr_branches, rotation = 'vertical')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interpolating_function(data, bins):\n",
    "    bin_centers = [np.mean([bins[i], bins[i + 1]]) for i in range(len(bins) - 1)]\n",
    "    intf = interpolate.interp1d(bin_centers, data, kind = \"linear\")\n",
    "    interpolated_function = lambda x: intf(x) if x > bin_centers[0] and x < bin_centers[-1] else 0\n",
    "    \n",
    "    return interpolated_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binned_data(df, branch):\n",
    "    data = df[branch].as_matrix()\n",
    "    weights = df[\"training_weight\"].as_matrix()\n",
    "    \n",
    "    # set the bin width\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    bin_width = max(2 * (q75 - q25) / len(data)**0.33, 0.005)\n",
    "\n",
    "    data_max = np.max(data)\n",
    "    data_min = np.min(data)\n",
    "    bins = np.arange(data_min, data_max + bin_width, bin_width)\n",
    "    \n",
    "    weights = weights / (np.sum(weights) * bin_width)\n",
    "    \n",
    "    hist = np.histogram(data, bins = bins, weights = weights)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_list_BDT(disc_pair, mandatory_branches, optional_branches, list_branches, pt_limits):\n",
    "    H1_name = disc_pair[0]\n",
    "    H0_name = disc_pair[1]\n",
    "    \n",
    "    # first assemble the list of branches that can serve as input: it will *always* contain the mandatory branches,\n",
    "    # and *can* contain some of the optional branches, if the name of the categories allows it\n",
    "    input_branches = [branch for branch in mandatory_branches]\n",
    "    \n",
    "    for optional_branch in optional_branches:\n",
    "        if (\"0j\" in H1_name or \"0j\" in H0_name) and (\"0j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)  \n",
    "        elif (\"1j\" in H1_name or \"1j\" in H0_name) and (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "        elif (\"2j\" in H1_name or \"2j\" in H0_name) and not (\"1j\" in optional_branch):\n",
    "            input_branches.append(optional_branch)\n",
    "            \n",
    "        # the fully inclusive categories (i.e. those with NO \"xxj\" in their name, can not use MELA, since there may\n",
    "        # be events with low number of jets contained)\n",
    "    \n",
    "    # get the training data for the BDT ...\n",
    "    H1_coll_train = FileCollection(collections[H1_name], 0.0, 0.5)\n",
    "    H0_coll_train = FileCollection(collections[H0_name], 0.0, 0.5)\n",
    "    \n",
    "    dtrain = get_data_dmatrix(H1_coll_train, H0_coll_train, allbranches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    # ... and the validation data as well\n",
    "    H1_coll_val = FileCollection(collections[H1_name], 0.5, 1.0)\n",
    "    H0_coll_val = FileCollection(collections[H0_name], 0.5, 1.0)\n",
    "    dval = get_data_dmatrix(H1_coll_val, H0_coll_val, allbranches, input_branches, list_branches, pt_limits)\n",
    "    \n",
    "    evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "    \n",
    "    # perform the training\n",
    "    # try different tree depths and choose the one that gives the best RMSE (i.e. avoid too deep trees to start with)\n",
    "        \n",
    "    params = {'eta': 0.01, 'silent': 1, 'gamma': 0.5, 'objective': 'binary:logistic'}\n",
    "    params['nthread'] = 4\n",
    "    params['eval_metric'] = 'rmse'\n",
    "    max_num_rounds = 2000\n",
    "    \n",
    "    best_loss = 1e6\n",
    "    best_imp = None\n",
    "    best_params = None\n",
    "    for tree_depth in range(1,8):\n",
    "        params['max_depth'] = tree_depth\n",
    "        \n",
    "        bst = xgb.train(params, dtrain, max_num_rounds, evals = evallist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "    \n",
    "        pred = bst.predict(dval)\n",
    "        cur_loss = np.sqrt(mean_squared_error(pred, dval.get_label()))\n",
    "        cur_imp = bst.get_fscore()\n",
    "\n",
    "        print \"for max_depth = \" + str(params['max_depth']) + \": loss = \" + str(cur_loss)\n",
    "        \n",
    "        if cur_loss < best_loss:\n",
    "            best_loss = cur_loss\n",
    "            best_imp = copy.copy(cur_imp)\n",
    "            best_params = copy.copy(params)\n",
    "            \n",
    "    # normalize the usage score w.r.t. the total score (i.e. sum of all individuals)\n",
    "    score_sum = sum([val for key, val in best_imp.iteritems()])\n",
    "    used_variables = {key: val / float(score_sum) for key, val in sorted(best_imp.iteritems(), key = lambda x: x[1], reverse = True)}           \n",
    "    return best_params, dtrain.feature_names, used_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_histogram(df, branch, label):\n",
    "    data = df[branch].as_matrix()\n",
    "    weights = df[\"training_weight\"].as_matrix()\n",
    "    \n",
    "    # set the bin width\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    bin_width = max(2 * (q75 - q25) / len(data)**0.33, 0.005)\n",
    "\n",
    "    data_max = np.max(data)\n",
    "    data_min = np.min(data)\n",
    "    bins = np.arange(data_min, data_max + bin_width, bin_width)\n",
    "    \n",
    "    weights = weights / (np.sum(weights) * bin_width)\n",
    "    \n",
    "    fig = plt.hist(data, bins = bins, weights = weights, alpha = 0.5, label = label)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_branch(disc_pair, branch, start_fraction = 0.0, end_fraction = 1.0):\n",
    "    H1_name = disc_pair[0]\n",
    "    H0_name = disc_pair[1]\n",
    "    \n",
    "    # get the training data for the BDT ...\n",
    "    H1_coll = FileCollection(collections[H1_name], start_fraction, end_fraction)\n",
    "    H0_coll = FileCollection(collections[H0_name], start_fraction, end_fraction)\n",
    "    \n",
    "    H1_df, H0_df = get_data(H1_coll, H0_coll, allbranches, allbranches, list_branches, pt_limits)\n",
    "    \n",
    "    plt.figure()\n",
    "    H1_hist = get_histogram(H1_df, branch, H1_name)\n",
    "    H0_hist = get_histogram(H0_df, branch, H0_name)\n",
    "    \n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_variables(discs):\n",
    "    plotframe = pd.DataFrame()\n",
    "    \n",
    "    for disc in discs:\n",
    "        _, _, implist = get_feature_importance_list_BDT(disc, candidate_branches, MELA_branches, list_branches, pt_limits)\n",
    "        \n",
    "        # cut the list to select only the 95% most important variables\n",
    "        cutimplist = {key: val for key, val in implist.iteritems() if val > 0.00}\n",
    "        curframe = pd.DataFrame(cutimplist, index = [len(plotframe)])\n",
    "        \n",
    "        plotframe = pd.concat([plotframe, curframe])\n",
    "        \n",
    "    plotframe = plotframe.fillna(0.0)\n",
    "    \n",
    "    print plotframe\n",
    "    print \"number of pre-selected input variables = \" + str(len(plotframe.columns))\n",
    "    \n",
    "    # start the plotting\n",
    "    parameters = plotframe.columns\n",
    "    plotdata = np.transpose(plotframe.as_matrix())\n",
    "    \n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize=(10,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(plotdata, cmap = 'Blues')\n",
    "    \n",
    "    # make axis labels\n",
    "    disclabels = []\n",
    "    for disc in discs:\n",
    "        if \"0j\" in disc[0] or \"0j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('0j', '', disc[0]) + \"_\" + re.sub('0j', '', disc[1]) + \"_0j\")\n",
    "        elif \"01j\" in disc[0] or \"01j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('01j', '', disc[0]) + \"_\" + re.sub('01j', '', disc[1]) + \"_01j\")\n",
    "        elif \"1j\" in disc[0] or \"1j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('1j', '', disc[0]) + \"_\" + re.sub('1j', '', disc[1]) + \"_1j\")\n",
    "        elif \"2j\" in disc[0] or \"2j\" in disc[1]:\n",
    "            disclabels.append('D_' + re.sub('2j', '', disc[0]) + \"_\" + re.sub('2j', '', disc[1]) + \"_2j\")\n",
    "        else:\n",
    "            disclabels.append('D_' + disc[0] + \"_\" + disc[1] + \"_2j\")\n",
    "            \n",
    "    disclabels = np.concatenate([[''], np.array(disclabels)])\n",
    "    parameters = np.concatenate([[''], np.array(parameters)])\n",
    "        \n",
    "    ax.set_xticklabels(disclabels, rotation = 'vertical')\n",
    "    ax.set_yticklabels(parameters)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    # sort the used variables according to their importance\n",
    "    sorted_implist = []\n",
    "    for key, val in sorted(cutimplist.iteritems(), key = lambda x: x[1], reverse = True):\n",
    "        sorted_implist.append((key, val))\n",
    "    \n",
    "    return fig, sorted_implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_variables(confhandler, impdict, threshold_fscore):\n",
    "    confhandler.new_section(impdict[\"discriminant\"])\n",
    "    cur_sec = confhandler.get_section(impdict[\"discriminant\"])\n",
    "\n",
    "    periodic_inputs = []\n",
    "    nonperiodic_inputs = []\n",
    "    for key, val in impdict.iteritems():\n",
    "        if val[0] > threshold_fscore and key is not \"discriminant\":\n",
    "            if \"phi\" in key or \"Phi\" in key:\n",
    "                periodic_inputs.append(key)\n",
    "            else:\n",
    "                nonperiodic_inputs.append(key)\n",
    "    cur_sec[\"nonperiodic_columns\"] = ConfigFileUtils.serialize_list(nonperiodic_inputs, lambda x: x)\n",
    "    cur_sec[\"periodic_columns\"] = ConfigFileUtils.serialize_list(periodic_inputs, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_varname(raw):\n",
    "    raw = raw.replace('(', '[')\n",
    "    raw = raw.replace(')', ']')\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_dir = \"/data_CMS/cms/wind/InputConfigurations/\"\n",
    "out_path = os.path.join(out_dir, \"inclusive_99_fullmassrange.conf\")\n",
    "threshold_fscore = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confhandler = ConfigFileHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZZPt', 0.08877805486284289),\n",
       " ('JetEta(JetPt|0)', 0.083854878931703),\n",
       " ('JetPt(JetPt|0)', 0.06099267959134422),\n",
       " ('ZZEta', 0.057887539216474944),\n",
       " ('PFMET', 0.05447671144718848),\n",
       " ('Z1Pt', 0.04863647333279704),\n",
       " ('ZZPhi', 0.046561016812806694),\n",
       " ('D_VBF2j_ggH_ME', 0.04437293862118896),\n",
       " ('ZZMassErr', 0.043150189043520235),\n",
       " ('ZZMass', 0.041106910143994854),\n",
       " ('Z2Mass', 0.04060815702678787),\n",
       " ('Z2Pt', 0.040254203201673236),\n",
       " ('Z1Mass', 0.03835572359424021),\n",
       " ('JetPt(JetPt|1)', 0.033529080524495214),\n",
       " ('JetPhi(JetPt|0)', 0.03330383718124045),\n",
       " ('D_VBF1j_ggH_ME', 0.03019869680637117),\n",
       " ('JetEta(JetPt|1)', 0.02548467540825356),\n",
       " ('D_WHh_ZHh_ME', 0.022057758828734616),\n",
       " ('JetEta(JetPt|2)', 0.021961225967339716),\n",
       " ('JetPhi(JetPt|1)', 0.021269407127342932),\n",
       " ('D_WHh_ggH_ME', 0.020223634462231518),\n",
       " ('D_VBF2j_WHh_ME', 0.019773147775721985),\n",
       " ('D_ZHh_ggH_ME', 0.019563993242699702),\n",
       " ('JetPt(JetPt|2)', 0.017665513635266673),\n",
       " ('D_VBF2j_ZHh_ME', 0.01303193628831148),\n",
       " ('JetPhi(JetPt|2)', 0.008398358941356286),\n",
       " ('JetPhi(JetPt|3)', 0.004874909500442442),\n",
       " ('nCleanedJetsPt30', 0.004697932587885126),\n",
       " ('JetPt(JetPt|3)', 0.002558120826964846),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.0022202558120826966),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.0020754565199903466),\n",
       " ('Z2Flav', 0.0019467460381304802),\n",
       " ('Z1Flav', 0.001882390797200547),\n",
       " ('JetEta(JetPt|3)', 0.001512348161853431),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0013192824390636313),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0012549271981336981),\n",
       " ('nExtraLep', 0.00016088810232483308)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZZMass', 0.10130758643024856),\n",
       " ('ZZPt', 0.08033762448384746),\n",
       " ('ZZEta', 0.07681564245810056),\n",
       " ('JetEta(JetPt|0)', 0.07246376811594203),\n",
       " ('JetPt(JetPt|0)', 0.06092624079021942),\n",
       " ('Z1Pt', 0.04961136750060724),\n",
       " ('ZZMassErr', 0.044652254878147515),\n",
       " ('PFMET', 0.043781880009715814),\n",
       " ('ZZPhi', 0.03957169459962756),\n",
       " ('Z2Pt', 0.035746093433730065),\n",
       " ('Z2Mass', 0.03445065176908752),\n",
       " ('Z1Mass', 0.033134968828434946),\n",
       " ('D_WHh_ggH_ME', 0.032952797344344587),\n",
       " ('D_VBF1j_ggH_ME', 0.030685774431220145),\n",
       " ('JetPt(JetPt|1)', 0.028762853210266375),\n",
       " ('JetPhi(JetPt|0)', 0.026920897093352766),\n",
       " ('JetEta(JetPt|2)', 0.025767144360780505),\n",
       " ('D_VBF2j_ggH_ME', 0.02471459800825844),\n",
       " ('JetPt(JetPt|2)', 0.021111650878471378),\n",
       " ('JetEta(JetPt|1)', 0.020727066634280623),\n",
       " ('D_WHh_ZHh_ME', 0.015788195287830945),\n",
       " ('D_ZHh_ggH_ME', 0.013946239170917335),\n",
       " ('D_VBF2j_WHh_ME', 0.01360213747874666),\n",
       " ('JetPhi(JetPt|1)', 0.012913934094405312),\n",
       " ('D_VBF2j_ZHh_ME', 0.011942352845923408),\n",
       " ('JetPhi(JetPt|2)', 0.010363533317140312),\n",
       " ('JetEta(JetPt|3)', 0.007711926159825115),\n",
       " ('nCleanedJetsPt30', 0.0052424904866002755),\n",
       " ('JetPt(JetPt|3)', 0.004635252206299085),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0035624645777669823),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.003420775645696705),\n",
       " ('JetPhi(JetPt|3)', 0.003420775645696705),\n",
       " ('Z2Flav', 0.003319569265646506),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.0024491943972148006),\n",
       " ('Z1Flav', 0.002428953121204761),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0007894097643915473),\n",
       " ('nExtraLep', 2.024127601003967e-05)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZZMass', 0.10272090756004609),\n",
       " ('ZZPt', 0.08461106679665574),\n",
       " ('JetEta(JetPt|0)', 0.06286744069248722),\n",
       " ('ZZEta', 0.06097669059647257),\n",
       " ('JetPt(JetPt|0)', 0.06014948742946616),\n",
       " ('ZZPhi', 0.05199562764040297),\n",
       " ('Z1Pt', 0.04842092824012526),\n",
       " ('Z2Mass', 0.044698513988596415),\n",
       " ('Z1Mass', 0.04443262725634435),\n",
       " ('PFMET', 0.04440308428609412),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.03731277142603917),\n",
       " ('ZZMassErr', 0.03654465419953322),\n",
       " ('D_ZHh_ggH_ME', 0.035126591627522234),\n",
       " ('D_VBF1j_ggH_ME', 0.032792696977754145),\n",
       " ('Z2Pt', 0.03004520074448285),\n",
       " ('JetPt(JetPt|1)', 0.028774853023723006),\n",
       " ('JetEta(JetPt|1)', 0.022748087092676297),\n",
       " ('D_VBF2j_ggH_ME', 0.02215722768767172),\n",
       " ('JetEta(JetPt|2)', 0.019734704127152943),\n",
       " ('JetPhi(JetPt|0)', 0.019143844722148366),\n",
       " ('JetPt(JetPt|2)', 0.015716860173121804),\n",
       " ('D_WHh_ggH_ME', 0.012614848296847765),\n",
       " ('JetPhi(JetPt|2)', 0.010989984933085173),\n",
       " ('D_WHh_ZHh_ME', 0.010369582557830364),\n",
       " ('D_VBF2j_WHh_ME', 0.009128777807320748),\n",
       " ('D_VBF2j_ZHh_ME', 0.008774262164318),\n",
       " ('JetEta(JetPt|3)', 0.008065230878312506),\n",
       " ('JetPhi(JetPt|1)', 0.008065230878312506),\n",
       " ('JetPt(JetPt|3)', 0.005524535436792815),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.005376820585541671),\n",
       " ('JetPhi(JetPt|3)', 0.004992761972288694),\n",
       " ('nCleanedJetsPt30', 0.003574699400277704),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.002038464947265798),\n",
       " ('Z2Flav', 0.0017134922745132796),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0015066914827616769),\n",
       " ('Z1Flav', 0.0013294336612603031),\n",
       " ('nExtraLep', 0.0005613164347543502)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHh\", \"ZHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHh_ZHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PFMET', 0.05654778887303852),\n",
       " ('D_WHh_ZHh_ME', 0.05609129814550642),\n",
       " ('ZZMassErr', 0.05352353780313837),\n",
       " ('JetPt(JetPt|0)', 0.047075606276747506),\n",
       " ('Z2Mass', 0.04553495007132668),\n",
       " ('JetEta(JetPt|0)', 0.044907275320970046),\n",
       " ('JetPhi(JetPt|1)', 0.04456490727532097),\n",
       " ('ZZMass', 0.04433666191155492),\n",
       " ('Z1Pt', 0.04365192582025677),\n",
       " ('JetPhi(JetPt|0)', 0.042738944365192585),\n",
       " ('Z1Mass', 0.04251069900142653),\n",
       " ('D_WHh_ggH_ME', 0.0385734664764622),\n",
       " ('ZZEta', 0.03754636233951498),\n",
       " ('JetEta(JetPt|1)', 0.035606276747503565),\n",
       " ('ZZPhi', 0.034293865905848785),\n",
       " ('JetPt(JetPt|1)', 0.03372325249643367),\n",
       " ('Z2Pt', 0.03320970042796006),\n",
       " ('D_ZHh_ggH_ME', 0.032924393723252496),\n",
       " ('ZZPt', 0.030813124108416547),\n",
       " ('JetPt(JetPt|2)', 0.02579172610556348),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.025677603423680456),\n",
       " ('JetPhi(JetPt|2)', 0.024308131241084167),\n",
       " ('D_VBF2j_ggH_ME', 0.021854493580599144),\n",
       " ('D_VBF2j_WHh_ME', 0.019514978601997145),\n",
       " ('JetEta(JetPt|2)', 0.018716119828815977),\n",
       " ('D_VBF2j_ZHh_ME', 0.014607703281027104),\n",
       " ('JetPhi(JetPt|3)', 0.013980028530670471),\n",
       " ('D_VBF1j_ggH_ME', 0.00804564907275321),\n",
       " ('nCleanedJetsPt30', 0.0077603423680456494),\n",
       " ('JetEta(JetPt|3)', 0.0077603423680456494),\n",
       " ('Z1Flav', 0.005078459343794579),\n",
       " ('JetPt(JetPt|3)', 0.0038801711840228247),\n",
       " ('Z2Flav', 0.0015977175463623395),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0014265335235378032),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.0012553495007132669),\n",
       " ('nExtraLep', 0.00034236804564907275),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.0002282453637660485)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JetEta(JetPt|0)', 0.10215739276788902),\n",
       " ('ZZEta', 0.07499872494517264),\n",
       " ('ZZMass', 0.07438669862804101),\n",
       " ('JetEta(JetPt|2)', 0.06477278522976487),\n",
       " ('D_VBF2j_ggH_ME', 0.05758147600346815),\n",
       " ('JetPt(JetPt|0)', 0.048044065894833475),\n",
       " ('JetEta(JetPt|1)', 0.03804763604835008),\n",
       " ('PFMET', 0.03774162288978426),\n",
       " ('D_WHh_ZHh_ME', 0.0342479726628245),\n",
       " ('ZZPt', 0.033431937573315654),\n",
       " ('Z2Pt', 0.03338093538022135),\n",
       " ('JetPt(JetPt|2)', 0.03322792880093844),\n",
       " ('D_WHh_ggH_ME', 0.03118784107716632),\n",
       " ('JetPhi(JetPt|0)', 0.0300402917325445),\n",
       " ('Z1Pt', 0.029861784056714438),\n",
       " ('ZZMassErr', 0.029683276380884378),\n",
       " ('Z2Mass', 0.029606773091242922),\n",
       " ('Z1Mass', 0.02690365685724486),\n",
       " ('ZZPhi', 0.026470138215943285),\n",
       " ('D_VBF1j_ggH_ME', 0.023231498954455043),\n",
       " ('JetPt(JetPt|1)', 0.021624929871984496),\n",
       " ('D_ZHh_ggH_ME', 0.02055388381700413),\n",
       " ('D_VBF2j_ZHh_ME', 0.016805222624572857),\n",
       " ('JetPhi(JetPt|1)', 0.014943642576630795),\n",
       " ('D_VBF2j_WHh_ME', 0.012215025246085582),\n",
       " ('JetPhi(JetPt|2)', 0.011398990156576732),\n",
       " ('JetEta(JetPt|3)', 0.010506451777426429),\n",
       " ('JetPt(JetPt|3)', 0.009996429846483398),\n",
       " ('nCleanedJetsPt30', 0.006885296067730913),\n",
       " ('JetPhi(JetPt|3)', 0.005074718212883154),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0039016677717141836),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.0019635844341306676),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.0015300657928290916),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.001402560310093334),\n",
       " ('Z1Flav', 0.0011220482480746672),\n",
       " ('Z2Flav', 0.0010710460549803642)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4bd5822dac4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VBF\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ZHh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-8da2a149a362>\u001b[0m in \u001b[0;36mplot_variables\u001b[0;34m(discs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdisc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiscs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_importance_list_BDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_branches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMELA_branches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_branches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt_limits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# cut the list to select only the 95% most important variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-01f47a894497>\u001b[0m in \u001b[0;36mget_feature_importance_list_BDT\u001b[0;34m(disc_pair, mandatory_branches, optional_branches, list_branches, pt_limits)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevallist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs_depscipy/3.0-fmblme3/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs_depscipy/3.0-fmblme3/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs_depscipy/3.0-fmblme3/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"VBF\", \"ZHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_VBF_ZHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JetEta(JetPt|0)', 0.10215739276788902),\n",
       " ('ZZEta', 0.07499872494517264),\n",
       " ('ZZMass', 0.07438669862804101),\n",
       " ('JetEta(JetPt|2)', 0.06477278522976487),\n",
       " ('D_VBF2j_ggH_ME', 0.05758147600346815),\n",
       " ('JetPt(JetPt|0)', 0.048044065894833475),\n",
       " ('JetEta(JetPt|1)', 0.03804763604835008),\n",
       " ('PFMET', 0.03774162288978426),\n",
       " ('D_WHh_ZHh_ME', 0.0342479726628245),\n",
       " ('ZZPt', 0.033431937573315654),\n",
       " ('Z2Pt', 0.03338093538022135),\n",
       " ('JetPt(JetPt|2)', 0.03322792880093844),\n",
       " ('D_WHh_ggH_ME', 0.03118784107716632),\n",
       " ('JetPhi(JetPt|0)', 0.0300402917325445),\n",
       " ('Z1Pt', 0.029861784056714438),\n",
       " ('ZZMassErr', 0.029683276380884378),\n",
       " ('Z2Mass', 0.029606773091242922),\n",
       " ('Z1Mass', 0.02690365685724486),\n",
       " ('ZZPhi', 0.026470138215943285),\n",
       " ('D_VBF1j_ggH_ME', 0.023231498954455043),\n",
       " ('JetPt(JetPt|1)', 0.021624929871984496),\n",
       " ('D_ZHh_ggH_ME', 0.02055388381700413),\n",
       " ('D_VBF2j_ZHh_ME', 0.016805222624572857),\n",
       " ('JetPhi(JetPt|1)', 0.014943642576630795),\n",
       " ('D_VBF2j_WHh_ME', 0.012215025246085582),\n",
       " ('JetPhi(JetPt|2)', 0.011398990156576732),\n",
       " ('JetEta(JetPt|3)', 0.010506451777426429),\n",
       " ('JetPt(JetPt|3)', 0.009996429846483398),\n",
       " ('nCleanedJetsPt30', 0.006885296067730913),\n",
       " ('JetPhi(JetPt|3)', 0.005074718212883154),\n",
       " ('ExtraLepEta(ExtraLepPt|0)', 0.0039016677717141836),\n",
       " ('ExtraLepPt(ExtraLepPt|0)', 0.0019635844341306676),\n",
       " ('nCleanedJetsPt30BTagged_bTagSF', 0.0015300657928290916),\n",
       " ('ExtraLepPhi(ExtraLepPt|0)', 0.001402560310093334),\n",
       " ('Z1Flav', 0.0011220482480746672),\n",
       " ('Z2Flav', 0.0010710460549803642)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"WHl\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_WHl_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ZHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ZHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHh\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHh_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ZHMET\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ZHMET_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHl\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHl_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ttHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ttHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ZHMET\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ZHMET_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHh\", \"ttHl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHh_ttHl_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"ggH\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_ggH_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"VBF\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_VBF_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, implist = plot_variables([(\"ttHl\", \"WHh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impdict = {convert_varname(entry[0]): [entry[1]] for entry in implist}\n",
    "impdict[\"discriminant\"] = \"D_ttHl_WHh_ML\"\n",
    "df = df.append(pd.DataFrame.from_dict(impdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_variables(confhandler, impdict, threshold_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the variable configuration\n",
    "confhandler.save_configuration(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"input_parameters_table_inclusive.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now plot the data contained in the table to have a global picture of the relevant input variables\n",
    "datacol_labels = [col for col in df.columns.tolist() if col != \"discriminant\"]\n",
    "variable_data = df[datacol_labels].as_matrix().transpose()\n",
    "datacol_labels = np.concatenate([[''], np.array(datacol_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminant_labels = np.concatenate([[''], df[\"discriminant\"].as_matrix()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(variable_data, interpolation = 'nearest', cmap = 'Blues', vmin = np.min(variable_data), vmax = np.max(variable_data))\n",
    "ax.set_xticklabels(discriminant_labels, rotation = 'vertical')\n",
    "ax.set_yticklabels(datacol_labels)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, \"input_variables_inclusive_fullmassrange.pdf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
