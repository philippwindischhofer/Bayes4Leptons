{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, Activation\n",
    "from keras.engine.topology import Input\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.engine.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(intra_op_parallelism_threads = 10, inter_op_parallelism_threads = 10, allow_soft_placement = True, device_count = {'CPU': 10})\n",
    "session = tf.Session(config = config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/09\n"
     ]
    }
   ],
   "source": [
    "from trainlib.FileCollection import FileCollection\n",
    "from trainlib.Preprocessor import Preprocessor\n",
    "from trainlib.PCAWhiteningPreprocessor import PCAWhiteningPreprocessor\n",
    "from trainlib.RNNPreprocessor import RNNPreprocessor\n",
    "from trainlib.ListPreprocessor import ListPreprocessor\n",
    "from trainlib.generator import Generator\n",
    "import trainlib.cuts\n",
    "import trainlib.cuts as cuts\n",
    "from trainlib.utils import read_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slightly extended version of the numpy-internal one with same name, also handles the case when the entries in the dataframe are actually numpy arrays themselves\n",
    "def as_matrix(df):\n",
    "    return np.array(df.as_matrix().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the generator for tests\n",
    "H1_stream = {\"/data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\" : cuts.no_cut}\n",
    "H0_stream = {\"/data_CMS/cms/wind/CJLST_NTuples/VBFH125/ZZ4lAnalysis.root\" : cuts.no_cut}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skimming /data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 110483 entries in total, 110483 of which will be used\n"
     ]
    }
   ],
   "source": [
    "# read some input data\n",
    "fcoll = FileCollection({\"/data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\" : cuts.no_cut}, 0.0, 1.0)\n",
    "setup_data = read_data(fcoll, 0, 10, branches = [\"JetPt\", \"JetEta\", \"JetPhi\", \"PFMET\", \"nCleanedJetsPt30\"])\n",
    "validation_data = read_data(fcoll, 400, 800, branches = [\"JetPt\", \"JetEta\", \"JetPhi\", \"PFMET\", \"nCleanedJetsPt30\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the preprocessor for the RNN\n",
    "nonperiodic_columns = [\"JetPt\", \"JetEta\"]\n",
    "periodic_columns = [\"JetPhi\"]\n",
    "sorted_column = \"JetPt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JetPt</th>\n",
       "      <th>JetEta</th>\n",
       "      <th>JetPhi</th>\n",
       "      <th>PFMET</th>\n",
       "      <th>nCleanedJetsPt30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[53.6443]</td>\n",
       "      <td>[-2.29227]</td>\n",
       "      <td>[2.54869]</td>\n",
       "      <td>40.490429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[36.2919, 21.1634]</td>\n",
       "      <td>[0.326643, -0.80063]</td>\n",
       "      <td>[2.83377, 1.15123]</td>\n",
       "      <td>40.096920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>44.240479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[55.005, 28.7824]</td>\n",
       "      <td>[1.21199, -2.61541]</td>\n",
       "      <td>[1.77548, -0.592928]</td>\n",
       "      <td>71.606529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[29.372]</td>\n",
       "      <td>[3.82245]</td>\n",
       "      <td>[-2.58757]</td>\n",
       "      <td>21.410542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[21.1895]</td>\n",
       "      <td>[-2.82564]</td>\n",
       "      <td>[-1.86381]</td>\n",
       "      <td>21.159580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>28.228645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[21.9638]</td>\n",
       "      <td>[-1.08136]</td>\n",
       "      <td>[-2.47143]</td>\n",
       "      <td>34.765644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[81.062]</td>\n",
       "      <td>[3.98602]</td>\n",
       "      <td>[1.68111]</td>\n",
       "      <td>54.827316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[31.6878, 28.9569, 27.7632]</td>\n",
       "      <td>[-2.06541, 1.83295, -0.914617]</td>\n",
       "      <td>[1.32394, 0.201612, 2.14285]</td>\n",
       "      <td>7.474819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         JetPt                          JetEta  \\\n",
       "0                    [53.6443]                      [-2.29227]   \n",
       "1           [36.2919, 21.1634]            [0.326643, -0.80063]   \n",
       "2                           []                              []   \n",
       "3            [55.005, 28.7824]             [1.21199, -2.61541]   \n",
       "4                     [29.372]                       [3.82245]   \n",
       "5                    [21.1895]                      [-2.82564]   \n",
       "6                           []                              []   \n",
       "7                    [21.9638]                      [-1.08136]   \n",
       "8                     [81.062]                       [3.98602]   \n",
       "9  [31.6878, 28.9569, 27.7632]  [-2.06541, 1.83295, -0.914617]   \n",
       "\n",
       "                         JetPhi      PFMET  nCleanedJetsPt30  \n",
       "0                     [2.54869]  40.490429                 1  \n",
       "1            [2.83377, 1.15123]  40.096920                 1  \n",
       "2                            []  44.240479                 0  \n",
       "3          [1.77548, -0.592928]  71.606529                 1  \n",
       "4                    [-2.58757]  21.410542                 0  \n",
       "5                    [-1.86381]  21.159580                 0  \n",
       "6                            []  28.228645                 0  \n",
       "7                    [-2.47143]  34.765644                 0  \n",
       "8                     [1.68111]  54.827316                 1  \n",
       "9  [1.32394, 0.201612, 2.14285]   7.474819                 1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skimming /data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 110483 entries in total, 55241 of which will be used\n",
      "skimming /data_CMS/cms/wind/CJLST_NTuples/VBFH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 62320 entries in total, 31160 of which will be used\n"
     ]
    }
   ],
   "source": [
    "testgen = Generator(H1_stream, H0_stream, nonperiodic_columns + periodic_columns, preprocessor = pre_rnn.process)\n",
    "setup_len = testgen.setup_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_rnn = RNNPreprocessor('RNN_test', nonperiodic_columns, periodic_columns, sorted_column, cuts.no_cut, PCAWhiteningPreprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 contains 55241 entries\n",
      "H0 contains 31160 entries\n",
      "using the following chunk sizes: (55 / 31)\n",
      "setting up list preprocessor on 86430 events\n",
      "86430 remaining after the cuts\n",
      "102669 remaining after the cuts\n",
      "found a maximum list length in the setup data of 9: will pad or truncate to this length from now on\n"
     ]
    }
   ],
   "source": [
    "pre_rnn.setup_generator(testgen.raw_generator_scrambled(), len_setupdata = setup_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skimming /data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 110483 entries in total, 55242 of which will be used\n",
      "skimming /data_CMS/cms/wind/CJLST_NTuples/VBFH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 62320 entries in total, 31160 of which will be used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86402"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valgen = Generator(H1_stream, H0_stream, nonperiodic_columns + periodic_columns, preprocessor = pre_rnn.process)\n",
    "valgen.setup_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 contains 55242 entries\n",
      "H0 contains 31160 entries\n",
      "using the following chunk sizes: (55 / 31)\n"
     ]
    }
   ],
   "source": [
    "for data in valgen.preprocessed_generator():\n",
    "    preprocessed_data = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_data = preprocessed_data[0]['RNN_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.29843354,  0.7812869 ,  0.4199647 , -1.35477984],\n",
       "        [-0.80170888,  1.27705646, -0.53867084,  1.29122496],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.01474688,  1.49829412,  1.35071456, -0.44997355],\n",
       "        [-0.52562273, -0.29844102, -1.40878177,  0.11286414],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.49698573,  0.21857388,  0.36759889, -1.37099385],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.802109  ,  0.1866557 , -0.63000894,  1.26859319],\n",
       "        [-0.30275208,  0.48944232,  1.39887333, -0.20636952],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.76447117,  0.92382056, -0.07303844,  1.4122771 ],\n",
       "        [-0.17393772, -1.96325231, -1.40693271, -0.21173874],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.59066015,  1.26537442, -0.16121565,  1.3928448 ],\n",
       "        [-0.71074134,  1.06110561, -0.54012287,  1.29300272],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test its whitening quality\n",
    "flattened_data = processed_data[:,:,0].flatten()\n",
    "quality_data = flattened_data[np.nonzero(flattened_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.019649608"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(quality_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93612128"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(quality_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skimming /data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 110483 entries in total, 55241 of which will be used\n",
      "skimming /data_CMS/cms/wind/CJLST_NTuples/VBFH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 62320 entries in total, 31160 of which will be used\n"
     ]
    }
   ],
   "source": [
    "nonperiodic_columns = [\"JetPt\", \"JetEta\"]\n",
    "periodic_columns = [\"JetPhi\"]\n",
    "sorted_column = \"JetPt\"\n",
    "fixed_size_columns = [\"PFMET\", \"nCleanedJetsPt30\"]\n",
    "testgen = Generator(H1_stream, H0_stream, nonperiodic_columns + periodic_columns + fixed_size_columns, preprocessor = None)\n",
    "setup_len = testgen.setup_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 contains 55241 entries\n",
      "H0 contains 31160 entries\n",
      "using the following chunk sizes: (55 / 31)\n",
      "setting up list preprocessor on 86430 events\n",
      "86430 remaining after the cuts\n",
      "102669 remaining after the cuts\n",
      "found a maximum list length in the setup data of 9: will pad or truncate to this length from now on\n"
     ]
    }
   ],
   "source": [
    "pre_rnn = RNNPreprocessor('RNN_test', nonperiodic_columns, periodic_columns, sorted_column, cuts.no_cut, PCAWhiteningPreprocessor)\n",
    "pre_rnn.setup_generator(testgen.raw_generator_scrambled(), len_setupdata = setup_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 contains 55241 entries\n",
      "H0 contains 31160 entries\n",
      "using the following chunk sizes: (55 / 31)\n",
      "setting up PCA whitening on 86430 events\n",
      "86430 remaining after the cuts\n"
     ]
    }
   ],
   "source": [
    "# set up the preprocessor for the remaining fixed-size input variables\n",
    "pre_fixed = PCAWhiteningPreprocessor('fixed_test', fixed_size_columns, cuts.no_cut)\n",
    "pre_fixed.setup_generator(testgen.raw_generator_scrambled(), len_setupdata = setup_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CombinedModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def build(self):\n",
    "        in_layer_lstm = Input(shape = (None, 4), name = 'Jet')\n",
    "        # number units = dimensionality of the output space\n",
    "        lstm = LSTM(units = 16, return_sequences = False)(in_layer_lstm)\n",
    "        out_layer_lstm = Dense(4, activation = 'tanh')(lstm)\n",
    "        \n",
    "        in_layer_dense = Input(shape = (2,), name = 'scalar_inputs')\n",
    "        \n",
    "        x = keras.layers.concatenate([out_layer_lstm, in_layer_dense])\n",
    "        x = Dense(128, activation = 'tanh')(x)\n",
    "        x = Dense(128, activation = 'tanh')(x)\n",
    "\n",
    "        out_layer = Dense(1, activation = 'tanh', name = 'target')(x)\n",
    "        \n",
    "        self.model = keras.engine.training.Model(inputs = [in_layer_lstm, in_layer_dense], outputs = [out_layer], name = 'combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CombinedPreprocessor(Preprocessor):\n",
    "    def __init__(self, name, scalar_inputs, scalar_preprocessor_basetype, list_inputs, list_preprocessor_basetype, cuts):\n",
    "        self.name = name\n",
    "        self.scalar_inputs = scalar_inputs\n",
    "        self.list_inputs = list_inputs # note: list inputs is of the form {input_group_name: [\"input_1\", ...], ...}\n",
    "        self.cuts = cuts\n",
    "        self.last_indices = None\n",
    "        \n",
    "        self.list_preprocessors = {}\n",
    "        self.scalar_preprocessor = scalar_preprocessor_basetype('scalar_inputs', self.scalar_inputs, self.cuts)\n",
    "        \n",
    "        self.processed_columns = []\n",
    "        \n",
    "        # construct the RNN preprocessors from the passed dictionary of list inputs:\n",
    "        for name, input_columns in self.list_inputs.iteritems():\n",
    "            periodic_columns = []\n",
    "            nonperiodic_columns = []\n",
    "            sorted_column = None\n",
    "            for input_column in input_columns:\n",
    "                # listen for the keyword \"Phi\" to classify input variables as being periodic\n",
    "                if \"Phi\" in input_column:\n",
    "                    periodic_columns.append(input_column)\n",
    "                else:\n",
    "                    nonperiodic_columns.append(input_column)\n",
    "                    \n",
    "                # listen for the keyword \"Pt\" to set the column as the one that is sorted\n",
    "                if \"Pt\" in input_column:\n",
    "                    sorted_column = input_column\n",
    "                    \n",
    "            print(\"for list input group '\" + name + \"': assigned periodic inputs \" + str(periodic_columns) + \n",
    "                \" and nonperiodic inputs \" + str(nonperiodic_columns) + \", sorting according to \" + sorted_column)\n",
    "            \n",
    "            list_pre = list_preprocessor_basetype(name, nonperiodic_columns, periodic_columns, sorted_column, self.cuts, scalar_preprocessor_basetype)\n",
    "            self.list_preprocessors[name] = list_pre\n",
    "            \n",
    "            self.processed_columns += nonperiodic_columns\n",
    "            self.processed_columns += periodic_columns\n",
    "            \n",
    "        self.processed_columns += self.scalar_inputs\n",
    "        print \"total processed columns: \" + str(self.processed_columns)\n",
    "            \n",
    "    def setup_generator(self, datagen, len_setupdata):\n",
    "        self.len_setupdata = len_setupdata\n",
    "        extracted_data = []\n",
    "        extracted_rows = 0\n",
    "        \n",
    "        for data in datagen:\n",
    "            extracted_data.append(data)\n",
    "            extracted_rows += len(data)\n",
    "            \n",
    "            if extracted_rows > self.len_setupdata:\n",
    "                break\n",
    "                \n",
    "        print \"setting up preprocessor on \" + str(extracted_rows) + \" events\"\n",
    "        \n",
    "        input_data = pd.concat(extracted_data)\n",
    "        input_data = input_data.reset_index(drop = True)\n",
    "        \n",
    "        self.setup(input_data)\n",
    "    \n",
    "    def setup(self, data):\n",
    "        cut_data = self._rowcol_cut(data)\n",
    "        print cut_data.columns\n",
    "        # in turn, set up all the list-type preprocessors as well as the separate scalar one\n",
    "        print \"setting up scalar preprocessor\"\n",
    "        self.scalar_preprocessor.setup(cut_data)\n",
    "        \n",
    "        for name, pre in self.list_preprocessors.iteritems():\n",
    "            print \"setting up list preprocessor for '\" + name + \"'\"\n",
    "            pre.setup(cut_data)\n",
    "    \n",
    "    def process(self, data):\n",
    "        cut_data = self._rowcol_cut(data)\n",
    "        self.last_indices = cut_data.index\n",
    "        \n",
    "        # call each preprocessor in turn, and in the end combine all their outputs into the final dictionary object\n",
    "        retval = self.scalar_preprocessor.process(cut_data)\n",
    "                \n",
    "        for name, pre in self.list_preprocessors.iteritems():\n",
    "            list_output = pre.process(cut_data)\n",
    "            retval.update(list_output)\n",
    "            \n",
    "        return retval\n",
    "    \n",
    "    def get_last_indices(self):\n",
    "        return self.last_indices\n",
    "    \n",
    "    def save(self, folder, filename):\n",
    "        # save separately the scalar preprocessor as well as those for the list inputs\n",
    "        self.scalar_preprocessor.save(folder, \"scalar_\" + filename)\n",
    "        \n",
    "        for name, pre in self.list_preprocessors.iteritems():\n",
    "            pre.save(folder, \"list_\" + name + \"_\" + filename)\n",
    "    \n",
    "    def load(self, folder, filename):\n",
    "        # load them back separately as well\n",
    "        self.scalar_preprocessor.load(folder, \"scalar_\" + filename)\n",
    "        \n",
    "        for name, pre in self.list_preprocessor.iteritems():\n",
    "            pre.load(folder, \"list_\" + name + \"_\" + filename)\n",
    "            \n",
    "    def _rowcol_cut(self, data):\n",
    "        data = data.loc[data.apply(self.cuts, axis = 1)]\n",
    "        \n",
    "        output_data = data.loc[:, self.processed_columns]\n",
    "        \n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA setup: ['PFMET', 'nCleanedJetsPt30']\n",
      "for list input group 'Jet': assigned periodic inputs ['JetPhi'] and nonperiodic inputs ['JetPt', 'JetEta'], sorting according to JetPt\n",
      "PCA setup: ['JetPt', 'JetEta', 'JetPhi_sin', 'JetPhi_cos']\n",
      "total processed columns: ['JetPt', 'JetEta', 'JetPhi', 'PFMET', 'nCleanedJetsPt30']\n"
     ]
    }
   ],
   "source": [
    "scalar_inputs = [\"PFMET\", \"nCleanedJetsPt30\"]\n",
    "list_inputs = {'Jet': [\"JetPt\", \"JetEta\", \"JetPhi\"]}\n",
    "\n",
    "pre = CombinedPreprocessor('combined_test', scalar_inputs, PCAWhiteningPreprocessor, list_inputs, RNNPreprocessor, cuts.no_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skimming /data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 110483 entries in total, 55241 of which will be used\n",
      "skimming /data_CMS/cms/wind/CJLST_NTuples/VBFH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 62320 entries in total, 31160 of which will be used\n",
      "H1 contains 55241 entries\n",
      "H0 contains 31160 entries\n",
      "using the following chunk sizes: (55 / 31)\n",
      "setting up preprocessor on 86430 events\n",
      "Index([u'JetPt', u'JetEta', u'JetPhi', u'PFMET', u'nCleanedJetsPt30'], dtype='object')\n",
      "setting up scalar preprocessor\n",
      "setting up PCA whitening on 86430 events\n",
      "86430 remaining after the cuts\n",
      "setting up list preprocessor for 'Jet'\n",
      "List: Index([u'JetPt', u'JetEta', u'JetPhi_sin', u'JetPhi_cos'], dtype='object')\n",
      "86430 remaining after the cuts\n",
      "setting up PCA whitening on 102669 events\n",
      "102669 remaining after the cuts\n",
      "found a maximum list length in the setup data of 9: will pad or truncate to this length from now on\n"
     ]
    }
   ],
   "source": [
    "testgen = Generator(H1_stream, H0_stream, pre.processed_columns, preprocessor = None)\n",
    "setup_len = testgen.setup_training_data()\n",
    "pre.setup_generator(testgen.raw_generator_scrambled(), len_setupdata = setup_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jet': array([[[-0.17588344, -1.00814199,  0.45338827, -1.33961868],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.49884474,  0.15300953,  0.81654179, -1.16422951],\n",
       "         [-0.78042543, -0.34356138, -1.23776233, -0.69459617],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.15054528,  0.54451889, -0.59877771, -1.29054272],\n",
       "         [-0.6386261 , -1.14728892, -0.46932915,  1.33859479],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.62763029,  1.70206451,  1.41390765, -0.14715672],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.77995038, -1.24109852,  1.12795126,  0.83604008],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.76553166, -0.46921799,  1.40529358,  0.02871465],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.33444655,  1.77126718, -0.7076636 , -1.23135054],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.58454549, -0.90475047, -1.10516   , -0.89294297],\n",
       "         [-0.63536394,  0.82301909, -1.27022517,  0.59577799],\n",
       "         [-0.65758717, -0.39566666, -0.10730424, -1.42045939],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ]]], dtype=float32),\n",
       " 'scalar_inputs': array([[ 0.42388057,  0.14295058],\n",
       "        [ 0.4038884 ,  0.1442416 ],\n",
       "        [ 0.61424563, -0.9394188 ],\n",
       "        [ 2.00473034,  0.04086499],\n",
       "        [-0.5456266 , -0.86451842],\n",
       "        [-0.55837665, -0.86369507],\n",
       "        [-0.19923365, -0.88688723],\n",
       "        [ 0.1328778 , -0.90833379],\n",
       "        [ 1.15226443,  0.09591417],\n",
       "        [-1.25347356,  0.25126807]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.process(setup_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = CombinedModel()\n",
    "mod.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.model.compile(loss = \"mean_squared_error\", optimizer = sgd, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skimming /data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 110483 entries in total, 55241 of which will be used\n",
      "skimming /data_CMS/cms/wind/CJLST_NTuples/VBFH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 62320 entries in total, 31160 of which will be used\n",
      "skimming /data_CMS/cms/wind/CJLST_NTuples/ggH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 110483 entries in total, 55242 of which will be used\n",
      "skimming /data_CMS/cms/wind/CJLST_NTuples/VBFH125/ZZ4lAnalysis.root\n",
      "collection set up: 1 files, 62320 entries in total, 31160 of which will be used\n"
     ]
    }
   ],
   "source": [
    "train_gen = Generator(H1_stream, H0_stream, pre.processed_columns, preprocessor = pre.process)\n",
    "training_len = train_gen.setup_training_data()\n",
    "val_gen = Generator(H1_stream, H0_stream, pre.processed_columns, preprocessor = pre.process)\n",
    "validation_len = val_gen.setup_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "H1 contains 55241 entries\n",
      "H0 contains 31160 entries\n",
      "using the following chunk sizes: (55 / 31)\n",
      "H1 contains 55242 entries\n",
      "H0 contains 31160 entries\n",
      "using the following chunk sizes: (55 / 31)\n",
      "99s - loss: 0.2055 - acc: 0.7147 - val_loss: 0.1888 - val_acc: 0.7227\n",
      "Epoch 2/5\n",
      "92s - loss: 0.1801 - acc: 0.7343 - val_loss: 0.1773 - val_acc: 0.7345\n",
      "Epoch 3/5\n",
      "93s - loss: 0.1749 - acc: 0.7366 - val_loss: 0.1741 - val_acc: 0.7319\n",
      "Epoch 4/5\n",
      "92s - loss: 0.1774 - acc: 0.7299 - val_loss: 0.1722 - val_acc: 0.7298\n",
      "Epoch 5/5\n",
      "93s - loss: 0.1712 - acc: 0.7353 - val_loss: 0.1680 - val_acc: 0.7407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34be470290>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.model.fit_generator(train_gen.preprocessed_generator(), steps_per_epoch = 128, epochs = 5, \n",
    "                        verbose = 2, validation_data = val_gen.preprocessed_generator(), validation_steps = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
