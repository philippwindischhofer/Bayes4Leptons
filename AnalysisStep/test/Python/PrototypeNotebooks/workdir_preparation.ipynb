{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from trainlib.ConfigFileHandler import ConfigFileHandler\n",
    "from trainlib.ConfigFileUtils import ConfigFileUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will be passed as argument!\n",
    "dest_path = \"/data_CMS/cms/wind/CJLST_NTuples_workdir_python/\"\n",
    "source_path = \"/data_CMS/cms/wind/CJLST_NTuples_prepared/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the needed folders:\n",
    "train_dir = os.path.join(dest_path, \"training/\")\n",
    "validation_dir = os.path.join(dest_path, \"validation/\")\n",
    "test_dir = os.path.join(dest_path, \"test/\")\n",
    "trainval_dir = os.path.join(dest_path, \"trainval/\")\n",
    "temp_dir = os.path.join(dest_path, \"temp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create these directories\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "    \n",
    "if not os.path.exists(validation_dir):\n",
    "    os.makedirs(validation_dir)\n",
    "    \n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "if not os.path.exists(trainval_dir):\n",
    "    os.makedirs(trainval_dir)\n",
    "    \n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_dir = \"/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/\"\n",
    "scrambler = os.path.join(bin_dir, \"run_scrambler\")\n",
    "chunk_extractor = os.path.join(bin_dir, \"run_chunk_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings_path = os.path.join(dest_path, \"settings.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confhandler = ConfigFileHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempting to load configuration file from /data_CMS/cms/wind/CJLST_NTuples_workdir_python/settings.conf\n"
     ]
    }
   ],
   "source": [
    "confhandler.load_configuration(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_file_name = confhandler.get_field(\"Global\", \"root_file_name\")\n",
    "source_dir = confhandler.get_field(\"Global\", \"source_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_files = [cur_file for cur_file in confhandler.get_sections() if \"Global\" not in cur_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "available_files = next(os.walk(source_path))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "used_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "currently generating training dataset: ggH125\n",
      "extracting 0.0 - 0.5 from ggH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.5 - 0.75 from ggH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.75 - 1.0 from ggH125\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "currently generating training dataset: ttH125\n",
      "extracting 0.0 - 0.5 from ttH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.5 - 0.75 from ttH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.75 - 1.0 from ttH125\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "currently generating training dataset: VBFH125\n",
      "extracting 0.0 - 0.5 from VBFH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.5 - 0.75 from VBFH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.75 - 1.0 from VBFH125\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "currently generating training dataset: WminusH125\n",
      "extracting 0.0 - 0.5 from WminusH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.5 - 0.75 from WminusH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.75 - 1.0 from WminusH125\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "currently generating training dataset: WplusH125\n",
      "extracting 0.0 - 0.5 from WplusH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.5 - 0.75 from WplusH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.75 - 1.0 from WplusH125\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "currently generating training dataset: ZH125\n",
      "extracting 0.0 - 0.5 from ZH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.5 - 0.75 from ZH125\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.75 - 1.0 from ZH125\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "currently generating training dataset: bkg\n",
      "extracting 0.0 - 0.5 from AllData\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.5 - 0.75 from AllData\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.75 - 1.0 from AllData\n",
      "extracting 0.0 - 0.05 from ZZTo4l\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.05 - 0.077 from ZZTo4l\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.077 - 1.0 from ZZTo4l\n",
      "extracting 0.0 - 0.007 from ggTo2e2mu_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.007 - 0.01 from ggTo2e2mu_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.01 - 1.0 from ggTo2e2mu_Contin_MCFM701\n",
      "extracting 0.0 - 0.007 from ggTo2e2tau_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.007 - 0.01 from ggTo2e2tau_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.01 - 1.0 from ggTo2e2tau_Contin_MCFM701\n",
      "extracting 0.0 - 0.007 from ggTo2mu2tau_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.007 - 0.01 from ggTo2mu2tau_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.01 - 1.0 from ggTo2mu2tau_Contin_MCFM701\n",
      "extracting 0.0 - 0.007 from ggTo4e_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.007 - 0.01 from ggTo4e_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.01 - 1.0 from ggTo4e_Contin_MCFM701\n",
      "extracting 0.0 - 0.007 from ggTo4mu_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.007 - 0.01 from ggTo4mu_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.01 - 1.0 from ggTo4mu_Contin_MCFM701\n",
      "extracting 0.0 - 0.007 from ggTo4tau_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.007 - 0.01 from ggTo4tau_Contin_MCFM701\n",
      "-- -- -- -- -- -- -- -- -- -- -- --\n",
      "extracting 0.01 - 1.0 from ggTo4tau_Contin_MCFM701\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for training_file in training_files:\n",
    "    sect = confhandler.get_section(training_file)\n",
    "    \n",
    "    print \"--------------------------------------------------\"\n",
    "    print \"currently generating training dataset: \" + training_file\n",
    "    \n",
    "    source_files = ConfigFileUtils.parse_list(sect[\"source\"], lambda x: x)\n",
    "    train_val_splits = ConfigFileUtils.parse_list(sect[\"train_val_split\"], lambda x: float(x))\n",
    "    val_test_splits = ConfigFileUtils.parse_list(sect[\"val_test_split\"], lambda x: float(x))\n",
    "    \n",
    "    # first split the needed files into 3 pieces, as dictated by the splits read from the config file\n",
    "    for source_file, train_val_split, val_test_split in zip(source_files, train_val_splits, val_test_splits):\n",
    "        \n",
    "        print \"extracting 0.0 - \" + str(train_val_split) + \" from \" + source_file\n",
    "        \n",
    "        dest_dir = os.path.join(train_dir, source_file)\n",
    "        if not os.path.exists(dest_dir):\n",
    "            os.makedirs(dest_dir)\n",
    "    \n",
    "        #output = sp.check_output([chunk_extractor, os.path.join(source_path, source_file, root_file_name),\n",
    "        #                         os.path.join(dest_dir, root_file_name), str(0.0), str(train_val_split)])      \n",
    "        #print output\n",
    "        \n",
    "        print \"-- -- -- -- -- -- -- -- -- -- -- --\"\n",
    "        \n",
    "        print \"extracting \" + str(train_val_split) + \" - \" + str(val_test_split) + \" from \" + source_file\n",
    "        \n",
    "        dest_dir = os.path.join(validation_dir, source_file)\n",
    "        if not os.path.exists(dest_dir):\n",
    "            os.makedirs(dest_dir)\n",
    "    \n",
    "        #output = sp.check_output([chunk_extractor, os.path.join(source_path, source_file, root_file_name),\n",
    "        #                         os.path.join(dest_dir, root_file_name), str(train_val_split), str(val_test_split)])      \n",
    "        #print output\n",
    "        \n",
    "        print \"-- -- -- -- -- -- -- -- -- -- -- --\"\n",
    "        \n",
    "        print \"extracting \" + str(val_test_split) + \" - 1.0 from \" + source_file\n",
    "        \n",
    "        dest_dir = os.path.join(test_dir, source_file)\n",
    "        if not os.path.exists(dest_dir):\n",
    "            os.makedirs(dest_dir)\n",
    "    \n",
    "        #output = sp.check_output([chunk_extractor, os.path.join(source_path, source_file, root_file_name),\n",
    "        #                         os.path.join(dest_dir, root_file_name), str(val_test_split), str(1.0)])      \n",
    "        #print output\n",
    "        \n",
    "        used_files.append(source_file)\n",
    "    \n",
    "    print \"--------------------------------------------------\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unused_files = [cur_file for cur_file in available_files if cur_file not in used_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy all unused files (i.e. those that will never end up in some combined training dataset) directly into the test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/VBFH120 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/VBFH124 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/VBFH126 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/VBFH130 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/WminusH120 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/WminusH124 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/WminusH126 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/WminusH130 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/WplusH120 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/WplusH124 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/WplusH126 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/WplusH130 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ZH120 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ZH130 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/bbH124 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/bbH125 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/bbH126 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/bbH130 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ggH120 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ggH124 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ggH126 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ggH130 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/tqH125 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ttH120 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ttH124 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ttH126 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n",
      "cp -r /data_CMS/cms/wind/CJLST_NTuples_prepared/ttH130 /data_CMS/cms/wind/CJLST_NTuples_workdir_python/test/\n"
     ]
    }
   ],
   "source": [
    "for unused_file in unused_files:\n",
    "    dest_dir = test_dir\n",
    "    source_dir = os.path.join(source_path, unused_file)\n",
    "    \n",
    "    print \"cp -r \" + source_dir + \" \" + dest_dir\n",
    "    #output = sp.check_output([\"cp\", \"-r\", \"source_dir\", \"dest_dir\"])      \n",
    "    #print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now have all the needed files split apart, can now proceed to combine them into the training \n",
    "# datasets that will end up in trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now building training dataset: ggH125\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ggH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ggH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ggH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ggH125/training/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ggH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ggH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ggH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ggH125/validation/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/trainval/ggH125/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ggH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ggH125/validation/ZZ4lAnalysis.root\n",
      "now building training dataset: ttH125\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ttH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ttH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ttH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ttH125/training/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ttH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ttH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ttH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ttH125/validation/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/trainval/ttH125/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ttH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ttH125/validation/ZZ4lAnalysis.root\n",
      "now building training dataset: VBFH125\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/VBFH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/VBFH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/VBFH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/VBFH125/training/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/VBFH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/VBFH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/VBFH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/VBFH125/validation/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/trainval/VBFH125/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/VBFH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/VBFH125/validation/ZZ4lAnalysis.root\n",
      "now building training dataset: WminusH125\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/WminusH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/WminusH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/WminusH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/WminusH125/training/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/WminusH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/WminusH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/WminusH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/WminusH125/validation/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/trainval/WminusH125/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/WminusH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/WminusH125/validation/ZZ4lAnalysis.root\n",
      "now building training dataset: WplusH125\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/WplusH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/WplusH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/WplusH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/WplusH125/training/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/WplusH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/WplusH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/WplusH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/WplusH125/validation/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/trainval/WplusH125/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/WplusH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/WplusH125/validation/ZZ4lAnalysis.root\n",
      "now building training dataset: ZH125\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ZH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ZH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ZH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ZH125/training/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ZH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ZH125/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/ZH125/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ZH125/validation/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/trainval/ZH125/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ZH125/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/ZH125/validation/ZZ4lAnalysis.root\n",
      "now building training dataset: bkg\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/bkg/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/AllData/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ZZTo4l/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ggTo2e2mu_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ggTo2e2tau_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ggTo2mu2tau_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ggTo4e_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ggTo4mu_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/training/ggTo4tau_Contin_MCFM701/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/bkg/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/bkg/training/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/bkg/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/AllData/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ZZTo4l/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ggTo2e2mu_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ggTo2e2tau_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ggTo2mu2tau_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ggTo4e_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ggTo4mu_Contin_MCFM701/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/validation/ggTo4tau_Contin_MCFM701/ZZ4lAnalysis.root\n",
      "/home/llr/cms/wind/cmssw/CMSSW_9_4_2/bin/slc6_amd64_gcc630/run_scrambler /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/bkg/validation/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/bkg/validation/ZZ4lAnalysis.root\n",
      "hadd /data_CMS/cms/wind/CJLST_NTuples_workdir_python/trainval/bkg/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/bkg/training/ZZ4lAnalysis.root /data_CMS/cms/wind/CJLST_NTuples_workdir_python/temp/scrambled/bkg/validation/ZZ4lAnalysis.root\n"
     ]
    }
   ],
   "source": [
    "for training_file in training_files:\n",
    "    print \"now building training dataset: \" + training_file\n",
    "    sect = confhandler.get_section(training_file)\n",
    "    source_folders = ConfigFileUtils.parse_list(sect[\"source\"], lambda x: x)\n",
    "    \n",
    "    for mode in [\"training\", \"validation\"]:\n",
    "\n",
    "        temp_dest_file = os.path.join(dest_path, temp_dir, training_file, mode, root_file_name)\n",
    "\n",
    "        source_files = [os.path.join(dest_path, mode, cur_file, root_file_name) for cur_file in source_folders]\n",
    "        source_files = \" \".join(source_files)\n",
    "\n",
    "        print \"hadd \" + temp_dest_file + \" \" + source_files\n",
    "        #output = sp.check_output([\"hadd\", temp_dest_file, source_files])      \n",
    "        #print output\n",
    "    \n",
    "        temp_scrambled_folder = os.path.join(dest_path, temp_dir, \"scrambled\", training_file, mode)\n",
    "        if not os.path.exists(temp_scrambled_folder):\n",
    "            os.makedirs(temp_scrambled_folder)\n",
    "            \n",
    "        temp_scrambled_file = os.path.join(temp_scrambled_folder, root_file_name)\n",
    "        \n",
    "        print scrambler + \" \" + temp_dest_file + \" \" + temp_scrambled_file\n",
    "        #output = sp.check_output([scrambler, temp_dest_file, temp_scrambled_file])      \n",
    "        #print output\n",
    "        \n",
    "    trainval_dest_folder = os.path.join(trainval_dir, training_file)\n",
    "    if not os.path.exists(trainval_dest_folder):\n",
    "        os.makedirs(trainval_dest_folder)\n",
    "        \n",
    "    print \"hadd \" + os.path.join(trainval_dest_folder, root_file_name) + \" \" + os.path.join(dest_path, temp_dir, \"scrambled\", training_file, \"training\", root_file_name) + \" \" + os.path.join(dest_path, temp_dir, \"scrambled\", training_file, \"validation\", root_file_name)\n",
    "        \n",
    "    #output = sp.check_output[\"hadd\", os.path.join(trainval_dest_folder, root_file_name),\n",
    "    #                         os.path.join(dest_path, temp_dir, \"scrambled\", training_file, \"training\", root_file_name),\n",
    "    #                         os.path.join(dest_path, temp_dir, \"scrambled\", training_file, \"validation\", root_file_name)]\n",
    "    #print output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
