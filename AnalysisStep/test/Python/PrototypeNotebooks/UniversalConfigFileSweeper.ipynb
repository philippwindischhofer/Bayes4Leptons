{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from trainlib.ConfigFileHandler import ConfigFileHandler\n",
    "from trainlib.ModelCollectionConfigFileHandler import ModelCollectionConfigFileHandler\n",
    "from trainlib.ModelFactory import ModelFactory\n",
    "from trainlib.ConfigFileUtils import ConfigFileUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calls 'callback'\n",
    "def iterate(iterables_running, iterables_fixed, callback):\n",
    "    if len(iterables_running) == 0:\n",
    "        return\n",
    "    \n",
    "    if len(iterables_running) > 1:\n",
    "        # do the iteration along the next dimension, and keep the others for later in the recursion\n",
    "        explicit_key = iterables_running.keys()[0]\n",
    "        explicit_iterable = iterables_running.pop(explicit_key)\n",
    "        iterables_fixed[explicit_key] = explicit_iterable\n",
    "        \n",
    "        for pos in explicit_iterable:\n",
    "            iterate(copy.deepcopy(iterables_running), copy.deepcopy(iterables_fixed), callback)\n",
    "    else:\n",
    "        # this is the last dimension along which need to iterate\n",
    "        explicit_iterable = copy.deepcopy(iterables_running)\n",
    "        iterables_fixed.update(explicit_iterable)\n",
    "        for pos in explicit_iterable.values()[0]:\n",
    "            callback(iterables_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SweepDimensionDict:\n",
    "    \n",
    "    def __init__(self, name, parameter, start_dict, end_dict, step_dict, aux):\n",
    "        self.names = [name]\n",
    "        self.parameters = [parameter]\n",
    "        self.cur_dicts = [start_dict]\n",
    "        self.end_dicts = [end_dict]\n",
    "        self.step_dicts = [step_dict]\n",
    "        self.auxs = [aux]\n",
    "        self.first_call = True\n",
    "        \n",
    "    def add(self, name, parameter, start_dict, end_dict, step_dict, aux):\n",
    "        self.names.append(name)\n",
    "        self.parameters.append(parameter)\n",
    "        self.cur_dicts.append(start_dict)\n",
    "        self.end_dicts.append(end_dict)\n",
    "        self.step_dicts.append(step_dict)\n",
    "        self.auxs.append(aux)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        if not self.first_call:\n",
    "            for cur_dict, step_dict, end_dict in zip(self.cur_dicts, self.step_dicts, self.end_dicts):\n",
    "                for key, step in step_dict.iteritems():\n",
    "                    if cur_dict[key] + step < end_dict[key]:\n",
    "                        cur_dict[key] += step\n",
    "                    else:\n",
    "                        raise StopIteration\n",
    "        self.first_call = False\n",
    "        return self.cur_dicts\n",
    "    \n",
    "    def cur(self):\n",
    "        return self.cur_dicts\n",
    "    \n",
    "    def to_strings(self):\n",
    "        retvals = []\n",
    "        for cur_dict in self.cur_dicts:\n",
    "            retval = \"\"\n",
    "            for key, val in cur_dict.iteritems():\n",
    "                retval += str(key) + \"_\" + str(val) + \"_\"\n",
    "            \n",
    "            retvals.append(retval[:-1])\n",
    "        return retvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SweepDimensionList:\n",
    "    \n",
    "    def __init__(self, name, parameter, start_list, end_list, aux):\n",
    "        self.names = [name]\n",
    "        self.parameters = [parameter]\n",
    "        self.cur_lists = [start_list]\n",
    "        self.auxs = [aux]\n",
    "        self.to_add_lists = [[entry for entry in end_list if entry not in start_list]]\n",
    "        self.first_call = True\n",
    "        \n",
    "    def add(self, name, parameter, start_list, end_list, aux):\n",
    "        self.names.append(name)\n",
    "        self.parameters.append(parameter)\n",
    "        self.cur_lists.append(start_list)\n",
    "        self.to_add_lists.append([entry for entry in end_list if entry not in start_list])\n",
    "        self.auxs.append(aux)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        if not self.first_call:\n",
    "            for to_add_list, cur_list in zip(self.to_add_lists, self.cur_lists):\n",
    "                if len(to_add_list) > 0:\n",
    "                    cur_list.append(to_add_list.pop())\n",
    "                else:\n",
    "                    raise StopIteration\n",
    "        self.first_call = False\n",
    "        return self.cur_lists\n",
    "    \n",
    "    def cur(self):\n",
    "        return self.cur_lists\n",
    "    \n",
    "    def to_strings(self):\n",
    "        retvals = []\n",
    "        \n",
    "        for cur_list, parameter in zip(self.cur_lists, self.parameters):\n",
    "            retvals.append(parameter + \"_\" + str(len(cur_list)))\n",
    "            \n",
    "        return retvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def augment_config(mcoll, parent_dir, iterables):\n",
    "    mconfhandler = ModelCollectionConfigFileHandler()\n",
    "    mconfhandler.ToConfiguration(mcoll)\n",
    "    \n",
    "    outname = \"\"\n",
    "    \n",
    "    # augment the config object, given the values in the iterable dict\n",
    "    for it in iterables.values():\n",
    "        values = it.cur()\n",
    "        behaviours = it.auxs\n",
    "        outname += it.to_strings()[0] # always the first one in a linked sweep determines the actual name of it\n",
    "        section_names = it.names\n",
    "        parameter_names = it.parameters\n",
    "        \n",
    "        # apply all the changes set forth in a (linked) sweep\n",
    "        for value, behaviour, section_name, parameter_name in zip(values, behaviours, section_names, parameter_names):\n",
    "            if isinstance(value, dict):\n",
    "                if behaviour == 'replace':\n",
    "                    mconfhandler.SetDict(section_name, parameter_name, value, lambda x: str(x))\n",
    "                elif behaviour == 'append':\n",
    "                    mconfhandler.AddDictEntry(section_name, parameter_name, value, lambda x: float(x), lambda x: str(x))\n",
    "            elif isinstance(value, list):\n",
    "                if behaviour == 'replace':\n",
    "                    mconfhandler.SetList(section_name, parameter_name, value, lambda x: x)\n",
    "                elif behaviour == 'append':\n",
    "                    mconfhandler.AddListEntry(section_name, parameter_name, value, lambda x: x, lambda x: x)\n",
    "\n",
    "    outpath = parent_dir + outname + \"/\"\n",
    "    \n",
    "    if not os.path.exists(outpath):\n",
    "        print \"creating \" + outpath\n",
    "        os.makedirs(outpath)\n",
    "        \n",
    "    mconfhandler.save_configuration(outpath + \"settings.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempting to load configuration file from /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/campaign.conf\n"
     ]
    }
   ],
   "source": [
    "parent_dir = \"/data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/\"\n",
    "confhandler = ConfigFileHandler()\n",
    "confhandler.load_configuration(parent_dir + \"campaign.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterables = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for section in confhandler.get_sections():\n",
    "    if '!' in section:\n",
    "        sweep_name = re.sub('!', '', section)\n",
    "        sweep_sections = ConfigFileUtils.parse_list(confhandler.get_field(section, 'variables'), lambda x: x)\n",
    "        \n",
    "        # now look for the sweep variables that belong to this sweep\n",
    "        for sweep_section in sweep_sections:\n",
    "            # this is a section that determines a new sweep direction, possibly linked\n",
    "            sweep_metadata = confhandler.get_field(sweep_section, 'variable').split(':')\n",
    "            sweep_scope = sweep_metadata[0]\n",
    "            sweep_parameter = sweep_metadata[1]\n",
    "\n",
    "            # request more information\n",
    "            sweep_behaviour = confhandler.get_field(sweep_section, 'behaviour')\n",
    "\n",
    "            if ConfigFileUtils.is_dict(confhandler.get_field(sweep_section, 'start')):\n",
    "                # will need a dictionary iterable\n",
    "                start_dict = ConfigFileUtils.parse_dict(confhandler.get_field(sweep_section, 'start'), lambda x: float(x))\n",
    "                end_dict = ConfigFileUtils.parse_dict(confhandler.get_field(sweep_section, 'end'), lambda x: float(x))\n",
    "                step_dict = ConfigFileUtils.parse_dict(confhandler.get_field(sweep_section, 'step'), lambda x: float(x))\n",
    "                \n",
    "                if sweep_name not in iterables:\n",
    "                    it = SweepDimensionDict(sweep_scope, sweep_parameter, start_dict, end_dict, step_dict, sweep_behaviour)\n",
    "                    iterables[sweep_name] = it\n",
    "                else:\n",
    "                    iterables[sweep_name].add(sweep_scope, sweep_parameter, start_dict, end_dict, step_dict, sweep_behaviour)\n",
    "            else:\n",
    "                # construct a list iterable instead\n",
    "                start_list = ConfigFileUtils.parse_list(confhandler.get_field(sweep_section, 'start'), lambda x: x)    \n",
    "                end_list = ConfigFileUtils.parse_list(confhandler.get_field(sweep_section, 'end'), lambda x: x)\n",
    "                \n",
    "                if sweep_name not in iterables:\n",
    "                    it = SweepDimensionList(sweep_scope, sweep_parameter, start_list, end_list, sweep_behaviour)\n",
    "                    iterables[sweep_name] = it\n",
    "                else:\n",
    "                    iterables[sweep_name].add(sweep_scope, sweep_parameter, start_list, end_list, sweep_behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA setup for 'D_VBF_ggH_2j_ML_input': ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_VBF2j_ggH_ME']\n",
      "PCAWhiteningPreprocessor for stream 'D_VBF_ggH_2j_ML_input'\n",
      "got the following list of hyperparams: {'number_layers': 2}\n",
      "building network with inputs: ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_VBF2j_ggH_ME']\n",
      "PCA setup for 'D_VBF_ggH_1j_ML_input': ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_VBF1j_ggH_ME']\n",
      "PCAWhiteningPreprocessor for stream 'D_VBF_ggH_1j_ML_input'\n",
      "got the following list of hyperparams: {'number_layers': 2}\n",
      "building network with inputs: ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_VBF1j_ggH_ME']\n",
      "PCA setup for 'D_WHh_ggH_2j_ML_input': ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_WHh_ggH_ME']\n",
      "PCAWhiteningPreprocessor for stream 'D_WHh_ggH_2j_ML_input'\n",
      "got the following list of hyperparams: {'number_layers': 2}\n",
      "building network with inputs: ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_WHh_ggH_ME']\n",
      "PCA setup for 'D_ZHh_ggH_2j_ML_input': ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_ZHh_ggH_ME']\n",
      "PCAWhiteningPreprocessor for stream 'D_ZHh_ggH_2j_ML_input'\n",
      "got the following list of hyperparams: {'number_layers': 2}\n",
      "building network with inputs: ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_ZHh_ggH_ME']\n",
      "PCA setup for 'D_WHh_ZHh_2j_ML_input': ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_WHh_ZHh_ME']\n",
      "PCAWhiteningPreprocessor for stream 'D_WHh_ZHh_2j_ML_input'\n",
      "got the following list of hyperparams: {'number_layers': 2}\n",
      "building network with inputs: ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_WHh_ZHh_ME']\n",
      "PCA setup for 'D_VBF_WHh_2j_ML_input': ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_VBF2j_WHh_ME']\n",
      "PCAWhiteningPreprocessor for stream 'D_VBF_WHh_2j_ML_input'\n",
      "got the following list of hyperparams: {'number_layers': 2}\n",
      "building network with inputs: ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_VBF2j_WHh_ME']\n",
      "PCA setup for 'D_VBF_ZHh_2j_ML_input': ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_VBF2j_ZHh_ME']\n",
      "PCAWhiteningPreprocessor for stream 'D_VBF_ZHh_2j_ML_input'\n",
      "got the following list of hyperparams: {'number_layers': 2}\n",
      "building network with inputs: ['PFMET', 'nCleanedJetsPt30', 'nCleanedJetsPt30BTagged_bTagSF', 'nExtraLep', 'D_VBF2j_ZHh_ME']\n"
     ]
    }
   ],
   "source": [
    "MC_path = \"/data_CMS/cms/wind/CJLST_NTuples/\"\n",
    "model_type = confhandler.get_field('global', 'model_type') \n",
    "\n",
    "if model_type == 'SimpleModel':\n",
    "    mcoll = ModelFactory.GenerateSimpleModelCollectionsReducedCategorySet(MC_path)\n",
    "elif model_type == 'CombinedModel':\n",
    "    mcoll = ModelFactory.GenerateCombinedModelCollectionsReducedCategorySet(MC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_1.0number_neurons_128.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_1.0number_neurons_256.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_1.0number_neurons_384.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_1.0number_neurons_512.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_2.0number_neurons_128.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_2.0number_neurons_256.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_2.0number_neurons_384.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_2.0number_neurons_512.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_3.0number_neurons_128.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_3.0number_neurons_256.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_3.0number_neurons_384.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_3.0number_neurons_512.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_4.0number_neurons_128.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_4.0number_neurons_256.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_4.0number_neurons_384.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_4.0number_neurons_512.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_5.0number_neurons_128.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_5.0number_neurons_256.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_5.0number_neurons_384.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_5.0number_neurons_512.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_6.0number_neurons_128.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_6.0number_neurons_256.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_6.0number_neurons_384.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_6.0number_neurons_512.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_7.0number_neurons_128.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_7.0number_neurons_256.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_7.0number_neurons_384.0/\n",
      "creating /data_CMS/cms/wind/180330_layer_neurons_sweep_checkpoint_evaluation/number_layers_7.0number_neurons_512.0/\n"
     ]
    }
   ],
   "source": [
    "iterate(iterables, {}, lambda it: augment_config(mcoll, parent_dir, it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
