{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import trainlib.utils as utils\n",
    "import trainlib.cuts as cuts\n",
    "from trainlib.SimpleModel import SimpleModel\n",
    "import inspect\n",
    "from trainlib.ModelFactory import ModelFactory\n",
    "from trainlib.ModelCollection import ModelCollection\n",
    "from trainlib.PCAWhiteningPreprocessor import PCAWhiteningPreprocessor\n",
    "from trainlib.config import TrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cuts_translation = {\"no_cut\": cuts.no_cut, \"mZZ_cut\": cuts.mZZ_cut, \"WHhadr_cut\": cuts.WHhadr_cut, \"ZHhadr_cut\": cuts.ZHhadr_cut}\n",
    "model_translation = {\"SimpleModel\": SimpleModel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IdentityDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IntegerDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        return int(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_dict = IdentityDict()\n",
    "int_dict = IntegerDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_dict(rawstring, translation_dict):\n",
    "    retdict = {}\n",
    "    for source in rawstring.split(','):\n",
    "        key, cmd = source.split(':')\n",
    "        retdict[key.strip()] = translation_dict.get(cmd.strip())\n",
    "        \n",
    "    return retdict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_list(rawstring, translation_dict):\n",
    "    retlist = []\n",
    "    for entry in rawstring.split(','):\n",
    "        retlist.append(entry.strip())\n",
    "        \n",
    "    return retlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_model(config, model):\n",
    "    model_section = config['[' + model]\n",
    "    \n",
    "    model_name = model\n",
    "    base_model = model_translation[model_section['base_model']]\n",
    "    input_columns = process_list(model_section['input_columns'], no_dict)\n",
    "    preprocessor_cuts = eval(model_section['preprocessor_cuts'])\n",
    "    \n",
    "    pre = PCAWhiteningPreprocessor(processed_columns = input_columns, cuts = preprocessor_cuts)\n",
    "    \n",
    "    mod = base_model(model_name, input_columns)\n",
    "    mod.build()\n",
    "    \n",
    "    return mod, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_model_collection(config, section, weight_path):\n",
    "    cur_sect = config[section]\n",
    "    \n",
    "    mcoll_name = section\n",
    "    H1_stream = process_dict(cur_sect['H1_stream'], cuts_translation)\n",
    "    H0_stream = process_dict(cur_sect['H0_stream'], cuts_translation)\n",
    "    model_names = process_list(cur_sect['models'], no_dict)\n",
    "    \n",
    "    mcoll = ModelCollection(mcoll_name, H1_stream, H0_stream)\n",
    "\n",
    "    for model in model_names:\n",
    "        mod, pre = process_model(config, model)\n",
    "        sett = TrainingConfig()\n",
    "        mcoll.add_model(pre, mod, sett)\n",
    "\n",
    "    if weight_path is not None:\n",
    "        mcoll.load_weights(weight_path + mcoll_name)\n",
    "        \n",
    "    return mcoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assemble_lambda_string(func):\n",
    "    func_string = str(inspect.getsourcelines(func)[0])\n",
    "    func_string = func_string.strip(\"['\\\\n']\").split(\" = \")[1]\n",
    "\n",
    "    return func_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assemble_dict(in_dict, translation_dict):\n",
    "    inverse_translation = {val: key for key, val in translation_dict.iteritems()}\n",
    "    \n",
    "    out_string = \"\"\n",
    "    \n",
    "    for key, val in in_dict.iteritems():\n",
    "        out_string += key + \": \"\n",
    "        out_string += inverse_translation.get(val) + \", \"\n",
    "    \n",
    "    # cut away the last two (superfluous) characters\n",
    "    return out_string[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assemble_list(in_list):\n",
    "    out_string = \"\"\n",
    "    \n",
    "    for entry in in_list:\n",
    "        out_string += entry + \", \"\n",
    "        \n",
    "    return out_string[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_config_model(config, model, preprocessor):    \n",
    "    model_name = model.name\n",
    "    section_name = '[' + model_name + ']'\n",
    "    base_model = model.__class__.__name__\n",
    "    input_columns = assemble_list(model.input_columns)\n",
    "    preprocessor_cuts = assemble_lambda_string(preprocessor.cuts)\n",
    "        \n",
    "    # make a new section for the model in the config file\n",
    "    config[section_name] = {}\n",
    "    cur_sect = config[section_name]\n",
    "    \n",
    "    cur_sect['base_model'] = base_model\n",
    "    cur_sect['input_columns'] = input_columns\n",
    "    cur_sect['preprocessor_cuts'] = preprocessor_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_config_model_collection(config, mcoll):\n",
    "    mcoll_name = mcoll.name\n",
    "    H1_stream = mcoll.H1_stream\n",
    "    H0_stream = mcoll.H0_stream\n",
    "    model_names = mcoll.model_dict.keys()\n",
    "    #weightpath = training_dir\n",
    "    \n",
    "    # make a new section in the config file\n",
    "    config[mcoll_name] = {}\n",
    "    cur_sect = config[mcoll_name]\n",
    "    \n",
    "    cur_sect['H1_stream'] = assemble_dict(H1_stream, cuts_translation)\n",
    "    cur_sect['H0_stream'] = assemble_dict(H0_stream, cuts_translation)\n",
    "    cur_sect['models'] = assemble_list(model_names)\n",
    "    \n",
    "    models = mcoll.model_dict.values()\n",
    "    preprocessors = mcoll.preprocessor_dict.values()\n",
    "    for model, preprocessor in zip(models, preprocessors):\n",
    "        make_config_model(config, model, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the following models belonging to this collection:\n",
      "D_VBF_ggH_2j_ML\n",
      "D_VBF_ggH_1j_ML\n",
      "now attempting to load model 'D_VBF_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ggH_ML/D_VBF_ggH_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_VBF_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ggH_ML/D_VBF_ggH_2j_ML/preprocessor.pkl\n",
      "now attempting to load model 'D_VBF_ggH_1j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ggH_ML/D_VBF_ggH_1j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_VBF_ggH_1j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ggH_ML/D_VBF_ggH_1j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_WHh_ggH_2j_ML\n",
      "now attempting to load model 'D_WHh_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_WHh_ggH_ML/D_WHh_ggH_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_WHh_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_WHh_ggH_ML/D_WHh_ggH_2j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_ZHh_ggH_2j_ML\n",
      "now attempting to load model 'D_ZHh_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_ZHh_ggH_ML/D_ZHh_ggH_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_ZHh_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_ZHh_ggH_ML/D_ZHh_ggH_2j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_WHh_ZHh_2j_ML\n",
      "now attempting to load model 'D_WHh_ZHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_WHh_ZHh_ML/D_WHh_ZHh_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_WHh_ZHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_WHh_ZHh_ML/D_WHh_ZHh_2j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_VBF_WHh_2j_ML\n",
      "now attempting to load model 'D_VBF_WHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_WHh_ML/D_VBF_WHh_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_VBF_WHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_WHh_ML/D_VBF_WHh_2j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_VBF_ZHh_2j_ML\n",
      "now attempting to load model 'D_VBF_ZHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ZHh_ML/D_VBF_ZHh_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_VBF_ZHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ZHh_ML/D_VBF_ZHh_2j_ML/preprocessor.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-23 16:07:46.286036: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-03-23 16:07:46.286062: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-03-23 16:07:46.286071: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    }
   ],
   "source": [
    "mcoll = ModelFactory.GenerateStandardModelCollections(SimpleModel, \"/data_CMS/cms/wind/CJLST_NTuples/\", \"/data_CMS/cms/wind/test_training_100epochs/training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config_outpath = \"/home/llr/cms/wind/cmssw/CMSSW_9_4_2/src/ZZAnalysis/AnalysisStep/test/Python/outconfig.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ModelCollectionsToConfigFile(mcoll, configpath):\n",
    "    config = configparser.ConfigParser()\n",
    "    \n",
    "    for model in mcoll:\n",
    "        make_config_model_collection(config, model)\n",
    "        \n",
    "    with open(configpath, 'w') as configfile:\n",
    "        config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ModelCollectionsFromConfigFile(configpath, weightpath):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(configpath)\n",
    "    \n",
    "    raw_sections = config.sections()\n",
    "    main_sections = [name for name in raw_sections if not name.startswith('[')]\n",
    "    \n",
    "    mcolls = []\n",
    "    \n",
    "    for section in main_sections:\n",
    "        mcolls.append(process_model_collection(config, section, weightpath))\n",
    "        \n",
    "    return mcolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ModelCollectionsToConfigFile(mcoll, config_outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs/6.0-fmblme/lib/python2.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the following models belonging to this collection:\n",
      "D_VBF_ggH_2j_ML\n",
      "D_VBF_ggH_1j_ML\n",
      "now attempting to load model 'D_VBF_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ggH_ML/D_VBF_ggH_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_VBF_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ggH_ML/D_VBF_ggH_2j_ML/preprocessor.pkl\n",
      "now attempting to load model 'D_VBF_ggH_1j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ggH_ML/D_VBF_ggH_1j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_VBF_ggH_1j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ggH_ML/D_VBF_ggH_1j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_WHh_ggH_2j_ML\n",
      "now attempting to load model 'D_WHh_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_WHh_ggH_ML/D_WHh_ggH_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_WHh_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_WHh_ggH_ML/D_WHh_ggH_2j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_ZHh_ggH_2j_ML\n",
      "now attempting to load model 'D_ZHh_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_ZHh_ggH_ML/D_ZHh_ggH_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_ZHh_ggH_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_ZHh_ggH_ML/D_ZHh_ggH_2j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_WHh_ZHh_2j_ML\n",
      "now attempting to load model 'D_WHh_ZHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_WHh_ZHh_ML/D_WHh_ZHh_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_WHh_ZHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_WHh_ZHh_ML/D_WHh_ZHh_2j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_VBF_WHh_2j_ML\n",
      "now attempting to load model 'D_VBF_WHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_WHh_ML/D_VBF_WHh_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_VBF_WHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_WHh_ML/D_VBF_WHh_2j_ML/preprocessor.pkl\n",
      "found the following models belonging to this collection:\n",
      "D_VBF_ZHh_2j_ML\n",
      "now attempting to load model 'D_VBF_ZHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ZHh_ML/D_VBF_ZHh_2j_ML/final.hdf5\n",
      "now attempting to load preprocessor settings for 'D_VBF_ZHh_2j_ML' from file '/data_CMS/cms/wind/test_training_100epochs/training/D_VBF_ZHh_ML/D_VBF_ZHh_2j_ML/preprocessor.pkl\n"
     ]
    }
   ],
   "source": [
    "mcoll2 = ModelCollectionsFromConfigFile(config_outpath, \"/data_CMS/cms/wind/test_training_100epochs/training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
